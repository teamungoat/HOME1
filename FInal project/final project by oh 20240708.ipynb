{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1UQRlq4u_OdTUvJLmUuy_DlgirrKt60ra","authorship_tag":"ABX9TyPbAKp0Mrt8h1wF+tDWleq+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"QZdJAqfXmNbB","executionInfo":{"status":"ok","timestamp":1721118008294,"user_tz":-540,"elapsed":8262,"user":{"displayName":"í¬ë³µì§œ","userId":"12410456823605642737"}}},"outputs":[],"source":["import math\n","import numpy as np\n","import pandas as pd\n","import random\n","import re\n","import torch\n","import urllib.request\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import PreTrainedTokenizerFast\n","import urllib.request\n","import zipfile\n","import os\n"]},{"cell_type":"code","source":["import zipfile"],"metadata":{"id":"TP6m-OYvy4zZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["folder ='/content/drive/MyDrive/01.á„ƒá…¦á„‹á…µá„á…¥/2.Validation/á„‹á…¯á†«á„á…¥á†«á„ƒá…¦á„‹á…µá„á…¥'"],"metadata":{"id":"pvUN3Wn8uKh_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def unzip_all_files_in_folder(folder_path, extract_to_base):\n","    # í´ë” ë‚´ì˜ ëª¨ë“  íŒŒì¼ë“¤ì„ ìˆœíšŒ\n","    for file_name in os.listdir(folder_path):\n","        # íŒŒì¼ì˜ ì „ì²´ ê²½ë¡œë¥¼ ìƒì„±\n","        file_path = os.path.join(folder_path, file_name)\n","\n","        # ZIP íŒŒì¼ì¸ì§€ í™•ì¸\n","        if zipfile.is_zipfile(file_path):\n","            # ZIP íŒŒì¼ì˜ ì´ë¦„ì„ ë”°ì„œ ì¶”ì¶œí•  ë””ë ‰í† ë¦¬ë¥¼ ìƒì„±\n","            extract_to = os.path.join(extract_to_base, os.path.splitext(file_name)[0])\n","\n","            # ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±\n","            if not os.path.exists(extract_to):\n","                os.makedirs(extract_to)\n","\n","            # ZIP íŒŒì¼ì„ ì½ê³  ì••ì¶• í•´ì œ\n","            with zipfile.ZipFile(file_path, 'r') as zip_ref:\n","                zip_ref.extractall(extract_to)\n","                print(f'{file_name} íŒŒì¼ì´ {extract_to} ê²½ë¡œë¡œ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œë˜ì—ˆìŠµë‹ˆë‹¤.')\n","\n","# ì‚¬ìš© ì˜ˆì œ\n","folder_path = '/content/drive/MyDrive/01.á„ƒá…¦á„‹á…µá„á…¥/2.Validation/á„‹á…¯á†«á„á…¥á†«á„ƒá…¦á„‹á…µá„á…¥'  # ZIP íŒŒì¼ë“¤ì´ ìˆëŠ” í´ë” ê²½ë¡œ\n","extract_to_base = '/content/drive/MyDrive/01.á„ƒá…¦á„‹á…µá„á…¥/2.Validation/á„‹á…¯á†«á„á…¥á†«á„ƒá…¦á„‹á…µá„á…¥'  # íŒŒì¼ì„ ì¶”ì¶œí•  ê¸°ë³¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ\n","\n","unzip_all_files_in_folder(folder_path, extract_to_base)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"is9Of-oHx3J0","executionInfo":{"status":"ok","timestamp":1720416554601,"user_tz":-540,"elapsed":140234,"user":{"displayName":"í¬ë³µì§œ","userId":"12410456823605642737"}},"outputId":"89e0a0d0-c0f2-47a2-95dc-bc8b2730002a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["VS_02. FACEBOOK.zip íŒŒì¼ì´ /content/drive/MyDrive/01.á„ƒá…¦á„‹á…µá„á…¥/2.Validation/á„‹á…¯á†«á„á…¥á†«á„ƒá…¦á„‹á…µá„á…¥/VS_02. FACEBOOK ê²½ë¡œë¡œ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œë˜ì—ˆìŠµë‹ˆë‹¤.\n","VS_04. BAND.zip íŒŒì¼ì´ /content/drive/MyDrive/01.á„ƒá…¦á„‹á…µá„á…¥/2.Validation/á„‹á…¯á†«á„á…¥á†«á„ƒá…¦á„‹á…µá„á…¥/VS_04. BAND ê²½ë¡œë¡œ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œë˜ì—ˆìŠµë‹ˆë‹¤.\n","VS_03. INSTAGRAM.zip íŒŒì¼ì´ /content/drive/MyDrive/01.á„ƒá…¦á„‹á…µá„á…¥/2.Validation/á„‹á…¯á†«á„á…¥á†«á„ƒá…¦á„‹á…µá„á…¥/VS_03. INSTAGRAM ê²½ë¡œë¡œ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œë˜ì—ˆìŠµë‹ˆë‹¤.\n","VS_05. NATEON.zip íŒŒì¼ì´ /content/drive/MyDrive/01.á„ƒá…¦á„‹á…µá„á…¥/2.Validation/á„‹á…¯á†«á„á…¥á†«á„ƒá…¦á„‹á…µá„á…¥/VS_05. NATEON ê²½ë¡œë¡œ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œë˜ì—ˆìŠµë‹ˆë‹¤.\n","VS_01. KAKAO.zip íŒŒì¼ì´ /content/drive/MyDrive/01.á„ƒá…¦á„‹á…µá„á…¥/2.Validation/á„‹á…¯á†«á„á…¥á†«á„ƒá…¦á„‹á…µá„á…¥/VS_01. KAKAO ê²½ë¡œë¡œ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œë˜ì—ˆìŠµë‹ˆë‹¤.\n"]}]},{"cell_type":"code","source":["!pip install datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"g4fWuZQp10I2","executionInfo":{"status":"ok","timestamp":1721118039686,"user_tz":-540,"elapsed":31396,"user":{"displayName":"í¬ë³µì§œ","userId":"12410456823605642737"}},"outputId":"d1890e3d-255e-4dcb-cdcc-55abd281f4a8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n","Collecting pyarrow>=15.0.0 (from datasets)\n","  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n","Collecting requests>=2.32.2 (from datasets)\n","  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n","Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, requests, pyarrow, dill, multiprocess, datasets\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.31.0\n","    Uninstalling requests-2.31.0:\n","      Successfully uninstalled requests-2.31.0\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 14.0.2\n","    Uninstalling pyarrow-14.0.2:\n","      Successfully uninstalled pyarrow-14.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n","google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n","ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-2.20.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-16.1.0 requests-2.32.3 xxhash-3.4.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pyarrow","requests"]},"id":"5436defdab4644b1a70af90e89031a8e"}},"metadata":{}}]},{"cell_type":"code","source":["import os\n","from datasets import Dataset\n","from tqdm import tqdm\n","import time\n","from datasets import load_dataset\n","import pandas as pd"],"metadata":{"id":"_54yHs3i1Wbl","executionInfo":{"status":"ok","timestamp":1721118890552,"user_tz":-540,"elapsed":1366,"user":{"displayName":"í¬ë³µì§œ","userId":"12410456823605642737"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["folder=['/content/drive/MyDrive/01.á„ƒá…¦á„‹á…µá„á…¥/2.Validation/á„‹á…¯á†«á„á…¥á†«á„ƒá…¦á„‹á…µá„á…¥/VS_01. KAKAO',\n","        '/content/drive/MyDrive/01.á„ƒá…¦á„‹á…µá„á…¥/2.Validation/á„‹á…¯á†«á„á…¥á†«á„ƒá…¦á„‹á…µá„á…¥/VS_02. FACEBOOK',\n","        '/content/drive/MyDrive/01.á„ƒá…¦á„‹á…µá„á…¥/2.Validation/á„‹á…¯á†«á„á…¥á†«á„ƒá…¦á„‹á…µá„á…¥/VS_03. INSTAGRAM',\n","        '/content/drive/MyDrive/01.á„ƒá…¦á„‹á…µá„á…¥/2.Validation/á„‹á…¯á†«á„á…¥á†«á„ƒá…¦á„‹á…µá„á…¥/VS_04. BAND',\n","        '/content/drive/MyDrive/01.á„ƒá…¦á„‹á…µá„á…¥/2.Validation/á„‹á…¯á†«á„á…¥á†«á„ƒá…¦á„‹á…µá„á…¥/VS_05. NATEON']"],"metadata":{"id":"bMq4vt_604bk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = {\"Q\": [], \"A\": [], \"id\": []}"],"metadata":{"id":"lMkRba-K2VcS","executionInfo":{"status":"aborted","timestamp":1721118040370,"user_tz":-540,"elapsed":3,"user":{"displayName":"í¬ë³µì§œ","userId":"12410456823605642737"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["id_counter = 1\n","for folder_path in folder:\n","    for file in tqdm(os.listdir(folder_path)):\n","        if file.endswith(\".txt\"):\n","            file_path = os.path.join(folder_path, file)\n","            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n","                lines = f.readlines()\n","                prev_line = \"\"\n","                prev_label = None\n","                for line in lines:\n","                    line = line.strip()\n","                    if line:\n","                        try:\n","                            label = int(line.split(\":\")[0])\n","                            text = line[len(str(label)) + 3 :].strip()\n","                            if prev_line == \"\":\n","                                prev_line = text\n","                            else:\n","                                data[\"id\"].append(id_counter)\n","                                data[\"Q\"].append(prev_line)\n","                                data[\"A\"].append(text)\n","                                id_counter += 1\n","                                prev_line = \"\"\n","                        except ValueError:\n","                            continue\n","\n","\n","# ë°ì´í„°ì…‹ ìƒì„±\n","dataset = Dataset.from_dict(data)\n","\n","# ë°ì´í„°ì…‹ì„ CSV íŒŒì¼ë¡œ ì €ì¥\n","df = pd.DataFrame(data)\n","csv_filename = \"makedata.csv\"\n","df.to_csv(csv_filename, index=False, encoding=\"utf-8\")\n","\n","print(dataset[0])\n","len(dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uH8QYJzyv0mv","executionInfo":{"status":"ok","timestamp":1720417558100,"user_tz":-540,"elapsed":266961,"user":{"displayName":"í¬ë³µì§œ","userId":"12410456823605642737"}},"outputId":"4e2f56ab-e7b1-4fd9-bcc2-1bb4a9179bbd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7605/7605 [03:16<00:00, 38.65it/s] \n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:18<00:00, 55.52it/s]\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 600/600 [00:09<00:00, 63.92it/s] \n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 204/204 [00:02<00:00, 69.00it/s] \n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 201/201 [00:02<00:00, 90.32it/s] \n"]},{"output_type":"stream","name":"stdout","text":["{'Q': 'ì˜¤ëŠ˜ ì €ë…ì— ì˜¤ëœë§Œì— ì˜í™” ê³ ê³ ?', 'A': 'ì˜¤ìš° ë„ˆë¬´ ì¢‹ì§€? ã…', 'id': 1}\n"]}]},{"cell_type":"code","source":["!pip install pytorch_lightning"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CBLOjiiG4gyf","executionInfo":{"status":"ok","timestamp":1721118159638,"user_tz":-540,"elapsed":106257,"user":{"displayName":"í¬ë³µì§œ","userId":"12410456823605642737"}},"outputId":"666f634e-08a9-47b0-9b57-66d278d2d0f1"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch_lightning\n","  Downloading pytorch_lightning-2.3.3-py3-none-any.whl (812 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m812.3/812.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (1.25.2)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2.3.0+cu121)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.66.4)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0.1)\n","Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2023.6.0)\n","Collecting torchmetrics>=0.7.0 (from pytorch_lightning)\n","  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (24.1)\n","Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.12.2)\n","Collecting lightning-utilities>=0.10.0 (from pytorch_lightning)\n","  Downloading lightning_utilities-0.11.5-py3-none-any.whl (26 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2.32.3)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.9.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (67.7.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (3.15.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (1.13.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (3.1.4)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.0.0->pytorch_lightning)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.0.0->pytorch_lightning)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.0.0->pytorch_lightning)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.0.0->pytorch_lightning)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.0.0->pytorch_lightning)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.0.0->pytorch_lightning)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.0.0->pytorch_lightning)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.0.0->pytorch_lightning)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.0.0->pytorch_lightning)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.0.0->pytorch_lightning)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.0.0->pytorch_lightning)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->pytorch_lightning)\n","  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->pytorch_lightning) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (2024.7.4)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->pytorch_lightning) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch_lightning\n","Successfully installed lightning-utilities-0.11.5 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 pytorch_lightning-2.3.3 torchmetrics-1.4.0.post0\n"]}]},{"cell_type":"code","source":["from pytorch_lightning import LightningModule"],"metadata":{"id":"oWfHL8Lk5fLQ","executionInfo":{"status":"ok","timestamp":1721119281410,"user_tz":-540,"elapsed":1092,"user":{"displayName":"í¬ë³µì§œ","userId":"12410456823605642737"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch\n","from pytorch_lightning import Trainer\n","from pytorch_lightning.callbacks import ModelCheckpoint\n","\n","from torch.utils.data import DataLoader, Dataset\n","from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\n","from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n","import re, os\n","from tqdm import tqdm\n","\n","\n","Q_TKN = \"<usr>\"\n","A_TKN = \"<sys>\"\n","BOS = \"</s>\"\n","EOS = \"</s>\"\n","MASK = \"<unused0>\"\n","SENT = \"<unused1>\"\n","PAD = \"<pad>\"\n","\n","save_dir = \"saved_models\"\n","os.makedirs(save_dir, exist_ok=True)\n","\n","\n","print(\"start1\")\n","\n","\n","class ChatbotDataset(Dataset):\n","    def __init__(self, chats, max_len=40):  # ë°ì´í„°ì…‹ì˜ ì „ì²˜ë¦¬ë¥¼ í•´ì£¼ëŠ” ë¶€ë¶„\n","        self._data = chats\n","        self.max_len = max_len\n","        self.q_token = Q_TKN\n","        self.a_token = A_TKN\n","        self.sent_token = SENT\n","        self.eos = EOS\n","        self.mask = MASK\n","        self.tokenizer = koGPT2_TOKENIZER\n","\n","    def __len__(self):  # chatbotdata ì˜ ê¸¸ì´ë¥¼ ë¦¬í„´í•œë‹¤.\n","        return len(self._data)\n","\n","    def __getitem__(self, idx):  # ë¡œë“œí•œ ì±—ë´‡ ë°ì´í„°ë¥¼ ì°¨ë¡€ì°¨ë¡€ DataLoaderë¡œ ë„˜ê²¨ì£¼ëŠ” ë©”ì„œë“œ\n","        turn = self._data.iloc[idx]\n","        q = turn[\"Q\"]  # ì§ˆë¬¸ì„ ê°€ì ¸ì˜¨ë‹¤.\n","        q = re.sub(r\"([?.!,])\", r\" \", q)  # êµ¬ë‘£ì ë“¤ì„ ì œê±°í•œë‹¤.\n","\n","        a = turn[\"A\"]  # ë‹µë³€ì„ ê°€ì ¸ì˜¨ë‹¤.\n","        a = re.sub(r\"([?.!,])\", r\" \", a)  # êµ¬ë‘£ì ë“¤ì„ ì œê±°í•œë‹¤.\n","\n","        q_toked = self.tokenizer.tokenize(self.q_token + q + self.sent_token)\n","        q_len = len(q_toked)\n","\n","        a_toked = self.tokenizer.tokenize(self.a_token + a + self.eos)\n","        a_len = len(a_toked)\n","\n","        # ì§ˆë¬¸ì˜ ê¸¸ì´ê°€ ìµœëŒ€ê¸¸ì´ë³´ë‹¤ í¬ë©´\n","        if q_len > self.max_len:\n","            a_len = self.max_len - q_len  # ë‹µë³€ì˜ ê¸¸ì´ë¥¼ ìµœëŒ€ê¸¸ì´ - ì§ˆë¬¸ê¸¸ì´\n","            if a_len <= 0:  # ì§ˆë¬¸ì˜ ê¸¸ì´ê°€ ë„ˆë¬´ ê¸¸ì–´ ì§ˆë¬¸ë§Œìœ¼ë¡œ ìµœëŒ€ ê¸¸ì´ë¥¼ ì´ˆê³¼ í•œë‹¤ë©´\n","                q_toked = q_toked[-(int(self.max_len / 2)) :]  # ì§ˆë¬¸ê¸¸ì´ë¥¼ ìµœëŒ€ê¸¸ì´ì˜ ë°˜ìœ¼ë¡œ\n","                q_len = len(q_toked)\n","                a_len = self.max_len - q_len  # ë‹µë³€ì˜ ê¸¸ì´ë¥¼ ìµœëŒ€ê¸¸ì´ - ì§ˆë¬¸ê¸¸ì´\n","            a_toked = a_toked[:a_len]\n","            a_len = len(a_toked)\n","\n","        # ì§ˆë¬¸ì˜ ê¸¸ì´ + ë‹µë³€ì˜ ê¸¸ì´ê°€ ìµœëŒ€ê¸¸ì´ë³´ë‹¤ í¬ë©´\n","        if q_len + a_len > self.max_len:\n","            a_len = self.max_len - q_len  # ë‹µë³€ì˜ ê¸¸ì´ë¥¼ ìµœëŒ€ê¸¸ì´ - ì§ˆë¬¸ê¸¸ì´\n","            if a_len <= 0:  # ì§ˆë¬¸ì˜ ê¸¸ì´ê°€ ë„ˆë¬´ ê¸¸ì–´ ì§ˆë¬¸ë§Œìœ¼ë¡œ ìµœëŒ€ ê¸¸ì´ë¥¼ ì´ˆê³¼ í•œë‹¤ë©´\n","                q_toked = q_toked[-(int(self.max_len / 2)) :]  # ì§ˆë¬¸ê¸¸ì´ë¥¼ ìµœëŒ€ê¸¸ì´ì˜ ë°˜ìœ¼ë¡œ\n","                q_len = len(q_toked)\n","                a_len = self.max_len - q_len  # ë‹µë³€ì˜ ê¸¸ì´ë¥¼ ìµœëŒ€ê¸¸ì´ - ì§ˆë¬¸ê¸¸ì´\n","            a_toked = a_toked[:a_len]\n","            a_len = len(a_toked)\n","\n","        # ë‹µë³€ labels = [mask, mask, ...., mask, ..., <bos>,..ë‹µë³€.. <eos>, <pad>....]\n","        labels = [\n","            self.mask,\n","        ] * q_len + a_toked[1:]\n","\n","        # mask = ì§ˆë¬¸ê¸¸ì´ 0 + ë‹µë³€ê¸¸ì´ 1 + ë‚˜ë¨¸ì§€ 0\n","        mask = [0] * q_len + [1] * a_len + [0] * (self.max_len - q_len - a_len)\n","        # ë‹µë³€ labelsì„ index ë¡œ ë§Œë“ ë‹¤.\n","        labels_ids = self.tokenizer.convert_tokens_to_ids(labels)\n","        # ìµœëŒ€ê¸¸ì´ë§Œí¼ PADDING\n","        while len(labels_ids) < self.max_len:\n","            labels_ids += [self.tokenizer.pad_token_id]\n","\n","        # ì§ˆë¬¸ + ë‹µë³€ì„ index ë¡œ ë§Œë“ ë‹¤.\n","        token_ids = self.tokenizer.convert_tokens_to_ids(q_toked + a_toked)\n","        # ìµœëŒ€ê¸¸ì´ë§Œí¼ PADDING\n","        while len(token_ids) < self.max_len:\n","            token_ids += [self.tokenizer.pad_token_id]\n","\n","        # ì§ˆë¬¸+ë‹µë³€, ë§ˆìŠ¤í¬, ë‹µë³€\n","        return (token_ids, np.array(mask), labels_ids)\n","\n","\n","def collate_batch(batch):\n","    data = [item[0] for item in batch]\n","    mask = [item[1] for item in batch]\n","    label = [item[2] for item in batch]\n","    return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","\n","\n","koGPT2_TOKENIZER = PreTrainedTokenizerFast.from_pretrained(\n","    \"skt/kogpt2-base-v2\",\n","    bos_token=BOS,\n","    eos_token=EOS,\n","    unk_token=\"<unk>\",\n","    pad_token=PAD,\n","    mask_token=MASK,\n",")\n","model = GPT2LMHeadModel.from_pretrained(\"skt/kogpt2-base-v2\")\n","\n","dataname = \"/content/drive/MyDrive/Colab Notebooks/makedata.csv\"  # Adjusted file path\n","Chatbot_Data = pd.read_csv(dataname)\n","Chatbot_Data = Chatbot_Data[:100]\n","Chatbot_Data.dropna(subset=[\"A\"], inplace=True)\n","Chatbot_Data.dropna(subset=[\"Q\"], inplace=True)\n","Chatbot_Data.dropna(subset=[\"id\"], inplace=True)\n","\n","\n","print(\"start3\")\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","train_set = ChatbotDataset(Chatbot_Data, max_len=40)\n","train_dataloader = DataLoader(\n","    train_set,\n","    batch_size=32,\n","    num_workers=0,\n","    shuffle=True,\n","    collate_fn=collate_batch,\n",")\n","\n","model.to(device)\n","\n","learning_rate = 3e-5\n","criterion = torch.nn.CrossEntropyLoss(reduction=\"none\")\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","num_epochs = 3\n","Sneg = -1e18\n","\n","for epoch in range(num_epochs):\n","    dataloader = tqdm(train_dataloader, desc=f\"Epoch {epoch}\")\n","    for batch_idx, samples in enumerate(dataloader):\n","        optimizer.zero_grad()\n","        token_ids, mask, label = samples\n","        token_ids, mask, label = token_ids.to(device), mask.to(device), label.to(device)\n","        out = model(token_ids)\n","        out = out.logits\n","        mask_3d = mask.unsqueeze(dim=2).repeat_interleave(repeats=out.shape[2], dim=2)\n","        mask_out = torch.where(mask_3d == 1, out, Sneg * torch.ones_like(out))\n","        loss = criterion(mask_out.transpose(2, 1), label)\n","        print(out.shape)\n","        print(label.shape)\n","        print(mask.shape)\n","        print(mask_3d.shape)\n","        print(mask_out.shape)\n","        print(mask_out.transpose(2, 1).shape)\n","        print(label.shape)\n","        avg_loss = loss.sum() / mask.sum()\n","        print('avg_loss', avg_loss)\n","        avg_loss.backward()\n","        optimizer.step()\n","\n","model_save_path = os.path.join(save_dir, \"chatbot_model.pth\")\n","torch.save(\n","    {\n","        \"model_state_dict\": model.state_dict(),\n","        \"optimizer_state_dict\": optimizer.state_dict(),\n","        \"epoch\": epoch,\n","    },\n","    model_save_path,\n",")\n","\n","print(\"Model saved at:\", model_save_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4AXMtFpD3XZq","executionInfo":{"status":"ok","timestamp":1721118930281,"user_tz":-540,"elapsed":13662,"user":{"displayName":"í¬ë³µì§œ","userId":"12410456823605642737"}},"outputId":"d30384a8-2f72-4364-f154-f4ce64ea7995","collapsed":true},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["start1\n"]},{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n"]},{"output_type":"stream","name":"stdout","text":["start3\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  4.24it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([32, 40, 51200])\n","torch.Size([32, 40])\n","torch.Size([32, 40])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 51200, 40])\n","torch.Size([32, 40])\n","avg_loss tensor(25.5422, device='cuda:0', grad_fn=<DivBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  3.52it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([32, 40, 51200])\n","torch.Size([32, 40])\n","torch.Size([32, 40])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 51200, 40])\n","torch.Size([32, 40])\n","avg_loss tensor(26.2511, device='cuda:0', grad_fn=<DivBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  3.34it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([32, 40, 51200])\n","torch.Size([32, 40])\n","torch.Size([32, 40])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 51200, 40])\n","torch.Size([32, 40])\n","avg_loss tensor(27.4932, device='cuda:0', grad_fn=<DivBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["torch.Size([4, 40, 51200])\n","torch.Size([4, 40])\n","torch.Size([4, 40])\n","torch.Size([4, 40, 51200])\n","torch.Size([4, 40, 51200])\n","torch.Size([4, 51200, 40])\n","torch.Size([4, 40])\n","avg_loss tensor(30.7330, device='cuda:0', grad_fn=<DivBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch 1:   0%|          | 0/4 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([32, 40, 51200])\n","torch.Size([32, 40])\n","torch.Size([32, 40])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 51200, 40])\n","torch.Size([32, 40])\n","avg_loss tensor(25.7929, device='cuda:0', grad_fn=<DivBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  3.94it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([32, 40, 51200])\n","torch.Size([32, 40])\n","torch.Size([32, 40])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 51200, 40])\n","torch.Size([32, 40])\n","avg_loss tensor(26.0282, device='cuda:0', grad_fn=<DivBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch 1:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  3.49it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([32, 40, 51200])\n","torch.Size([32, 40])\n","torch.Size([32, 40])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 51200, 40])\n","torch.Size([32, 40])\n","avg_loss tensor(24.1489, device='cuda:0', grad_fn=<DivBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["torch.Size([4, 40, 51200])\n","torch.Size([4, 40])\n","torch.Size([4, 40])\n","torch.Size([4, 40, 51200])\n","torch.Size([4, 40, 51200])\n","torch.Size([4, 51200, 40])\n","torch.Size([4, 40])\n","avg_loss tensor(17.3010, device='cuda:0', grad_fn=<DivBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch 2:   0%|          | 0/4 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([32, 40, 51200])\n","torch.Size([32, 40])\n","torch.Size([32, 40])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 51200, 40])\n","torch.Size([32, 40])\n","avg_loss tensor(23.8283, device='cuda:0', grad_fn=<DivBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  3.91it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([32, 40, 51200])\n","torch.Size([32, 40])\n","torch.Size([32, 40])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 51200, 40])\n","torch.Size([32, 40])\n","avg_loss tensor(23.5509, device='cuda:0', grad_fn=<DivBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch 2:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  3.49it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([32, 40, 51200])\n","torch.Size([32, 40])\n","torch.Size([32, 40])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 51200, 40])\n","torch.Size([32, 40])\n","avg_loss tensor(23.1537, device='cuda:0', grad_fn=<DivBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.75it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([4, 40, 51200])\n","torch.Size([4, 40])\n","torch.Size([4, 40])\n","torch.Size([4, 40, 51200])\n","torch.Size([4, 40, 51200])\n","torch.Size([4, 51200, 40])\n","torch.Size([4, 40])\n","avg_loss tensor(22.8056, device='cuda:0', grad_fn=<DivBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Model saved at: saved_models/chatbot_model.pth\n"]}]},{"cell_type":"code","source":["# print('out',out.shape)\n","#         print(label.shape)\n","#         print(mask.shape)\n","#         print(mask_3d.shape)\n","#         print(mask_out.shape)\n","#         print(mask_out.transpose(2, 1).shape)\n","#         print(label.shape)"],"metadata":{"id":"WQSiO6_ZYxi3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["token_ids\n","token_ids.shape\n","out.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZEB_whnIUy1r","executionInfo":{"status":"ok","timestamp":1720676809170,"user_tz":-540,"elapsed":449,"user":{"displayName":"í¬ë³µì§œ","userId":"12410456823605642737"}},"outputId":"2262e9d4-b1d6-4a3f-e1ac-bf5d9feb05e4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4, 40, 51200])"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["label.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NzYMY2dyVNtR","executionInfo":{"status":"ok","timestamp":1720676840753,"user_tz":-540,"elapsed":328,"user":{"displayName":"í¬ë³µì§œ","userId":"12410456823605642737"}},"outputId":"bae9426c-1b04-4fa2-afa2-4a5ca4081ff0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4, 40])"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["mask_3d.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0QLvLOfFVp2j","executionInfo":{"status":"ok","timestamp":1720676953714,"user_tz":-540,"elapsed":332,"user":{"displayName":"í¬ë³µì§œ","userId":"12410456823605642737"}},"outputId":"4a117ea9-efd7-4702-ad21-cf1f06c0227c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4, 40, 51200])"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["mask_out.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oNpy4RVQV7XJ","executionInfo":{"status":"ok","timestamp":1720677118114,"user_tz":-540,"elapsed":301,"user":{"displayName":"í¬ë³µì§œ","userId":"12410456823605642737"}},"outputId":"2b63bf30-2a31-46f3-9df2-433e719513d4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4, 40, 51200])"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["mask_out.transpose(2, 1).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rRpJzpyLWg7U","executionInfo":{"status":"ok","timestamp":1720677182464,"user_tz":-540,"elapsed":300,"user":{"displayName":"í¬ë³µì§œ","userId":"12410456823605642737"}},"outputId":"37b0bcea-feee-4179-dce9-e9b2597fe4c8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4, 51200, 40])"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["mask.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FbtQ6_vfWTn3","executionInfo":{"status":"ok","timestamp":1720677126054,"user_tz":-540,"elapsed":327,"user":{"displayName":"í¬ë³µì§œ","userId":"12410456823605642737"}},"outputId":"af755d3e-525e-4553-ee57-2a3507670feb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4, 40])"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["train_set[0]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HEyNUW19qUNV","executionInfo":{"status":"ok","timestamp":1720676897437,"user_tz":-540,"elapsed":350,"user":{"displayName":"í¬ë³µì§œ","userId":"12410456823605642737"}},"outputId":"a80f999f-8bf1-4fe5-e302-f800cdf3d4bd","collapsed":true},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([2,\n","  10070,\n","  44596,\n","  12474,\n","  20486,\n","  10584,\n","  17577,\n","  739,\n","  10,\n","  4,\n","  9114,\n","  8092,\n","  12371,\n","  18364,\n","  739,\n","  739,\n","  608,\n","  1,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3],\n"," array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n"," [9,\n","  9,\n","  9,\n","  9,\n","  9,\n","  9,\n","  9,\n","  9,\n","  9,\n","  9114,\n","  8092,\n","  12371,\n","  18364,\n","  739,\n","  739,\n","  608,\n","  1,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3])"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["import torch\n","from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jwffEEwq2CQa","outputId":"85bbee90-1d6f-4745-c656-190d742203ad","executionInfo":{"status":"ok","timestamp":1721118963454,"user_tz":-540,"elapsed":3702,"user":{"displayName":"í¬ë³µì§œ","userId":"12410456823605642737"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n"]},{"output_type":"execute_result","data":{"text/plain":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(51200, 768)\n","    (wpe): Embedding(1024, 768)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0-11): 12 x GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=51200, bias=False)\n",")"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["from transformers import PreTrainedTokenizerFast\n","tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\", bos_token='</s>', eos_token='</s>', unk_token='<unk>', pad_token='<pad>', mask_token='<mask>')\n","tokenizer.tokenize(\"ì•ˆë…•í•˜ì„¸ìš”. í•œêµ­ì–´ GPT-2 ì…ë‹ˆë‹¤.ğŸ˜¤:)l^o\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2oz1Dn9gsXdy","executionInfo":{"status":"ok","timestamp":1721119116339,"user_tz":-540,"elapsed":2368,"user":{"displayName":"í¬ë³µì§œ","userId":"12410456823605642737"}},"outputId":"54927440-2ff6-42c1-975c-f797be4db8a2"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n"]},{"output_type":"execute_result","data":{"text/plain":["['â–ì•ˆë…•',\n"," 'í•˜',\n"," 'ì„¸',\n"," 'ìš”.',\n"," 'â–í•œêµ­ì–´',\n"," 'â–G',\n"," 'P',\n"," 'T',\n"," '-2',\n"," 'â–ì…',\n"," 'ë‹ˆë‹¤.',\n"," 'ğŸ˜¤',\n"," ':)',\n"," 'l^o']"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch\n","from pytorch_lightning import Trainer\n","from pytorch_lightning.callbacks import ModelCheckpoint\n","from torch.utils.data import DataLoader, Dataset\n","from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\n","from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n","import re"],"metadata":{"id":"OeUHJl6GsnnD","executionInfo":{"status":"ok","timestamp":1721119357282,"user_tz":-540,"elapsed":521,"user":{"displayName":"í¬ë³µì§œ","userId":"12410456823605642737"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["Q_TKN = \"<usr>\"\n","A_TKN = \"<sys>\"\n","BOS = '</s>'\n","EOS = '</s>'\n","MASK = '<unused0>'\n","SENT = '<unused1>'\n","PAD = '<pad>'"],"metadata":{"id":"xz2ZFxXGtX5E","executionInfo":{"status":"ok","timestamp":1721119377651,"user_tz":-540,"elapsed":729,"user":{"displayName":"í¬ë³µì§œ","userId":"12410456823605642737"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["koGPT2_TOKENIZER = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n","            bos_token=BOS, eos_token=EOS, unk_token='<unk>',\n","            pad_token=PAD, mask_token=MASK)\n","model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IbnCZi8RtbaP","executionInfo":{"status":"ok","timestamp":1721119396465,"user_tz":-540,"elapsed":3270,"user":{"displayName":"í¬ë³µì§œ","userId":"12410456823605642737"}},"outputId":"5f60454a-a86b-4035-a0fa-c3489707f210"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n"]}]},{"cell_type":"code","source":["with torch.no_grad():\n","    while 1:\n","        q = input(\"user > \").strip()\n","        if q == \"quit\":\n","            break\n","        a = \"\"\n","        while 1:\n","            input_ids = torch.LongTensor(koGPT2_TOKENIZER.encode(Q_TKN + q + SENT + A_TKN + a)).unsqueeze(dim=0)\n","            pred = model(input_ids)\n","            pred = pred.logits\n","            gen = koGPT2_TOKENIZER.convert_ids_to_tokens(torch.argmax(pred, dim=-1).squeeze().numpy().tolist())[-1]\n","            if gen == EOS:\n","                break\n","            a += gen.replace(\"â–\", \" \")\n","        print(\"Chatbot > {}\".format(a.strip()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lN-JY3KSqc5f","outputId":"eb3501aa-ddb5-4ae0-8aca-cccf85a35a6d"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["user > ì•ˆë‡½\n"]}]},{"cell_type":"code","source":["# 1 ë°ì´í„° ë” ì°¾ê¸°\n","# 2 ë°ì´í„° ì¦ì‹\n","# 3 ë ˆê·¸?? ì–´ë–»ê²Œ ì“°ëŠ”ì§€ ì°¾ì•„ë³´ê¸°\n","# 4 íŒŒì´í† ì¹˜ ê³µë¶€í•˜ê¸°\n","# 4 í”„ë¡ íŠ¸ ì—”ì§€ë‹ˆì–´ë§ìœ¼ë¡œ ëŒ€í™” í†¤ ë°”ê¾¸ê¸° ex)ê³ ë¶„ê³ ë¶„, ê²¸ì†"],"metadata":{"id":"TMqoJbBukt-a"},"execution_count":null,"outputs":[]}]}