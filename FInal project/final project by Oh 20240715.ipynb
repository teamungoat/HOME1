{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1dZEBhswrfRghj7Y72B5zJG__WEqpX2HY","authorship_tag":"ABX9TyOABeWreSrT1FcBh065mvul"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XEGocmhFgYbi","executionInfo":{"status":"ok","timestamp":1721032155965,"user_tz":-540,"elapsed":23867,"user":{"displayName":"크복짜","userId":"12410456823605642737"}},"outputId":"4059dac4-547c-4d33-876d-96fc84960a80"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting nlpaug\n","  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.25.2)\n","Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.0.3)\n","Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.31.0)\n","Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (5.1.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.12.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (3.15.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.66.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2024.7.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->nlpaug) (1.16.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.5)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (1.7.1)\n","Installing collected packages: nlpaug\n","Successfully installed nlpaug-1.1.11\n","Collecting konlpy\n","  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting JPype1>=0.7.0 (from konlpy)\n","  Downloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (488 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.6/488.6 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.4)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.25.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (24.1)\n","Installing collected packages: JPype1, konlpy\n","Successfully installed JPype1-1.5.0 konlpy-0.6.0\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"]}],"source":["!pip install nlpaug\n","!pip install konlpy\n","!pip install nltk\n"]},{"cell_type":"code","source":["import pandas as pd\n","import nlpaug.augmenter.word as naw\n","import nlpaug.augmenter.char as nac\n","from konlpy.tag import Okt\n","\n","# 데이터 준비\n","data = {\n","    'Q': [\"안녕하세요?\", \"오늘 날씨는 어떤가요?\", \"당신의 이름은 무엇인가요?\"],\n","    'A': [\"안녕하세요. 만나서 반갑습니다.\", \"오늘 날씨는 맑습니다.\", \"저는 인공지능 챗봇입니다.\"]\n","}\n","\n","df = pd.DataFrame(data)\n","print(\"Original Data:\")\n","print(df)\n","\n","# KoNLPy의 Okt 형태소 분석기 사용\n","okt = Okt()\n","\n","# 한국어 문장을 토크나이즈하는 함수\n","def tokenize(text):\n","    return ' '.join(okt.morphs(text))\n","\n","# 한국어 문장 디토크나이즈하는 함수\n","def detokenize(tokens):\n","    return ''.join(tokens)\n","\n","# NLPAug 설정 (랜덤 단어 삭제)\n","aug = naw.RandomWordAug(action=\"delete\")\n","\n","# 증강 함수\n","def augment_text_korean(df, col, augmenter, n=1):\n","    augmented_texts = []\n","    for text in df[col]:\n","        tokens = tokenize(text)\n","        augmented = augmenter.augment(tokens, n=n)\n","        augmented_texts.append(detokenize(augmented))\n","    return augmented_texts\n","\n","# 질문과 답변 증강\n","df['Q_aug'] = augment_text_korean(df, 'Q', aug)\n","df['A_aug'] = augment_text_korean(df, 'A', aug)\n","\n","print(\"\\nAugmented Data:\")\n","print(df[['Q_aug', 'A_aug']])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GFquIXhRgfPX","executionInfo":{"status":"ok","timestamp":1721032387720,"user_tz":-540,"elapsed":324,"user":{"displayName":"크복짜","userId":"12410456823605642737"}},"outputId":"890e9098-67c2-47f4-da2f-e6e41e5724dc"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Data:\n","                Q                  A\n","0          안녕하세요?  안녕하세요. 만나서 반갑습니다.\n","1    오늘 날씨는 어떤가요?       오늘 날씨는 맑습니다.\n","2  당신의 이름은 무엇인가요?     저는 인공지능 챗봇입니다.\n","\n","Augmented Data:\n","       Q_aug      A_aug\n","0          ?   . 반갑습니다.\n","1  오늘 날씨 어떤?      날씨 는.\n","2   당신 의 이름?  는 인공 입니다.\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import nlpaug.augmenter.word as naw\n","from konlpy.tag import Okt\n","\n","# 데이터 로드\n","file_path = '/content/drive/MyDrive/Colab Notebooks/makedata.csv'\n","df = pd.read_csv(file_path)\n","\n","# 데이터 확인\n","print(\"Original Data:\")\n","print(df.head())\n","\n","# KoNLPy의 Okt 형태소 분석기 사용\n","okt = Okt()\n","\n","# 한국어 문장을 토크나이즈하는 함수\n","def tokenize(text):\n","    return okt.morphs(text)\n","\n","# 한국어 문장 디토크나이즈하는 함수\n","def detokenize(tokens):\n","    return ' '.join(tokens)\n","\n","# NLPAug 설정 (랜덤 단어 삭제)\n","aug = naw.RandomWordAug(action=\"delete\")\n","\n","# 증강 함수\n","def augment_text_korean(text, augmenter, n=1):\n","    tokens = tokenize(text)\n","    augmented = augmenter.augment(tokens, n=n)\n","    return detokenize(augmented)\n","\n","# 데이터 증강\n","df['Q_aug'] = df['Q'].apply(lambda x: augment_text_korean(x, aug))\n","df['A_aug'] = df['A'].apply(lambda x: augment_text_korean(x, aug))\n","\n","# 증강된 데이터 확인\n","print(\"\\nAugmented Data:\")\n","print(df[['Q', 'Q_aug', 'A', 'A_aug']].head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c8Moy-exg6u9","executionInfo":{"status":"ok","timestamp":1721032762905,"user_tz":-540,"elapsed":225368,"user":{"displayName":"크복짜","userId":"12410456823605642737"}},"outputId":"fe4f6236-9c50-46e4-ad02-7f099eeba188"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Data:\n","                                 Q                          A  id\n","0               오늘 저녁에 오랜만에 영화 고고?                오우 너무 좋지? ㅎ   1\n","1                        몇 시에 퇴근해?        난 3시면 퇴근하지요 ㅎ 자기는 ?   2\n","2  나는 5시 인데 회사 일이 많아서 조금 더 늦을 수 있어     그럼 영화관 가기는 그렇고 집에서 볼까?   3\n","3           좋지 좋지 ㅎ 집에서 치맥 하면서 볼까?  너무 좋지 하하 상상만 해도 벌써 힐링인데 ㅎ   4\n","4           근데 자기 다이어트 한다며 ㅋ 괜찮겠어?             맛있으면 0칼로리라잖아 ㅎ   5\n","\n","Augmented Data:\n","                                 Q                              Q_aug  \\\n","0               오늘 저녁에 오랜만에 영화 고고?             오늘 저녁 에 오랜 만 에 영화 고고 ?   \n","1                        몇 시에 퇴근해?                       몇 시 에 퇴근 해 ?   \n","2  나는 5시 인데 회사 일이 많아서 조금 더 늦을 수 있어  나 는 5시 인데 회사 일이 많아서 조금 더 늦 을 수 있어   \n","3           좋지 좋지 ㅎ 집에서 치맥 하면서 볼까?           좋지 좋지 ㅎ 집 에서 치맥 하면서 볼까 ?   \n","4           근데 자기 다이어트 한다며 ㅋ 괜찮겠어?            근데 자기 다이어트 한다며 ㅋ 괜찮겠어 ?   \n","\n","                           A                        A_aug  \n","0                오우 너무 좋지? ㅎ                 오우 너무 좋지 ? ㅎ  \n","1        난 3시면 퇴근하지요 ㅎ 자기는 ?       난 3시 면 퇴근 하지요 ㅎ 자기 는 ?  \n","2     그럼 영화관 가기는 그렇고 집에서 볼까?    그럼 영화관 가기 는 그렇고 집 에서 볼까 ?  \n","3  너무 좋지 하하 상상만 해도 벌써 힐링인데 ㅎ  너무 좋지 하하 상상 만 해도 벌써 힐링 인데 ㅎ  \n","4             맛있으면 0칼로리라잖아 ㅎ            맛있으면 0 칼로리 라 잖아 ㅎ  \n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import nlpaug.augmenter.word as naw\n","from konlpy.tag import Okt\n","\n","# 데이터 로드\n","file_path = '/content/drive/MyDrive/Colab Notebooks/makedata.csv'\n","df = pd.read_csv(file_path)\n","\n","# 데이터 확인\n","print(\"Original Data:\")\n","print(df.head())\n","\n","# KoNLPy의 Okt 형태소 분석기 사용\n","okt = Okt()\n","\n","# 한국어 문장을 토크나이즈하는 함수\n","def tokenize(text):\n","    return okt.morphs(text)\n","\n","# 한국어 문장 디토크나이즈하는 함수\n","def detokenize(tokens):\n","    return ' '.join(tokens)\n","\n","# NLPAug 설정 (랜덤 단어 삭제)\n","aug = naw.RandomWordAug(action=\"delete\")\n","\n","# 증강 함수\n","def augment_text_korean(text, augmenter, n=1):\n","    tokens = tokenize(text)\n","    augmented = augmenter.augment(tokens, n=n)\n","    if isinstance(augmented, list):\n","        augmented = augmented[0]\n","    return detokenize(augmented)\n","\n","# 데이터 증강\n","df['Q_aug'] = df['Q'].apply(lambda x: augment_text_korean(x, aug))\n","df['A_aug'] = df['A'].apply(lambda x: augment_text_korean(x, aug))\n","\n","# 증강된 데이터 확인\n","print(\"\\nAugmented Data:\")\n","print(df[['Q', 'Q_aug', 'A', 'A_aug']].head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GrlRIASaiHP4","executionInfo":{"status":"ok","timestamp":1721034865942,"user_tz":-540,"elapsed":209816,"user":{"displayName":"크복짜","userId":"12410456823605642737"}},"outputId":"d1d10f46-9710-4ba3-beb9-2939adf1b54a"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Data:\n","                                 Q                          A  id\n","0               오늘 저녁에 오랜만에 영화 고고?                오우 너무 좋지? ㅎ   1\n","1                        몇 시에 퇴근해?        난 3시면 퇴근하지요 ㅎ 자기는 ?   2\n","2  나는 5시 인데 회사 일이 많아서 조금 더 늦을 수 있어     그럼 영화관 가기는 그렇고 집에서 볼까?   3\n","3           좋지 좋지 ㅎ 집에서 치맥 하면서 볼까?  너무 좋지 하하 상상만 해도 벌써 힐링인데 ㅎ   4\n","4           근데 자기 다이어트 한다며 ㅋ 괜찮겠어?             맛있으면 0칼로리라잖아 ㅎ   5\n","\n","Augmented Data:\n","                                 Q Q_aug                          A    A_aug\n","0               오늘 저녁에 오랜만에 영화 고고?   오 늘                오우 너무 좋지? ㅎ      오 우\n","1                        몇 시에 퇴근해?     몇        난 3시면 퇴근하지요 ㅎ 자기는 ?        난\n","2  나는 5시 인데 회사 일이 많아서 조금 더 늦을 수 있어     나     그럼 영화관 가기는 그렇고 집에서 볼까?      그 럼\n","3           좋지 좋지 ㅎ 집에서 치맥 하면서 볼까?   좋 지  너무 좋지 하하 상상만 해도 벌써 힐링인데 ㅎ      너 무\n","4           근데 자기 다이어트 한다며 ㅋ 괜찮겠어?   근 데             맛있으면 0칼로리라잖아 ㅎ  맛 있 으 면\n"]}]},{"cell_type":"code","source":["if isinstance(augmented, list):\n","    augmented = augmented[0]\n"],"metadata":{"id":"DVwYXKBNqLRZ"},"execution_count":null,"outputs":[]}]}