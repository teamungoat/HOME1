{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1Qh3jdGPTdDvC8JrN1PfpbN4U2CeWsnpF","authorship_tag":"ABX9TyOA25HMdvCRpXyX9R/VMEj1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"bdb75de324854b95aab378a0706c5080":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5aed3385d84f45fdb3292b365dd85d8b","IPY_MODEL_048e8e1bdcdf492781ab93a0803d4492","IPY_MODEL_56bb996cd6004cdf88ee59b4c9897a6b"],"layout":"IPY_MODEL_a2eb50d55d514335b36ce94b25b32d11"}},"5aed3385d84f45fdb3292b365dd85d8b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3c0b619e4044312a451a31fbc93312c","placeholder":"​","style":"IPY_MODEL_731a415653374b75ae18f984f554b01a","value":"Epoch 2: 100%"}},"048e8e1bdcdf492781ab93a0803d4492":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec492490d6644fdeb968305cce6b9229","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d3461e7ff76446928a3e0412f1923cfe","value":7}},"56bb996cd6004cdf88ee59b4c9897a6b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_55d6042cecb34ac8aaf8f075b0a8ec17","placeholder":"​","style":"IPY_MODEL_622a670c4ccf431398cb05679b3b66ff","value":" 7/7 [02:28&lt;00:00,  0.05it/s, v_num=6]"}},"a2eb50d55d514335b36ce94b25b32d11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"b3c0b619e4044312a451a31fbc93312c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"731a415653374b75ae18f984f554b01a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec492490d6644fdeb968305cce6b9229":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3461e7ff76446928a3e0412f1923cfe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"55d6042cecb34ac8aaf8f075b0a8ec17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"622a670c4ccf431398cb05679b3b66ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"QZdJAqfXmNbB","executionInfo":{"status":"ok","timestamp":1721019599279,"user_tz":-540,"elapsed":5820,"user":{"displayName":"크복짜","userId":"12410456823605642737"}}},"outputs":[],"source":["import math\n","import numpy as np\n","import pandas as pd\n","import random\n","import re\n","import torch\n","import urllib.request\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import PreTrainedTokenizerFast\n","import urllib.request\n","import zipfile\n","import os\n"]},{"cell_type":"code","source":["import zipfile"],"metadata":{"id":"TP6m-OYvy4zZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["folder ='/content/drive/MyDrive/01.데이터/2.Validation/원천데이터'"],"metadata":{"id":"pvUN3Wn8uKh_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def unzip_all_files_in_folder(folder_path, extract_to_base):\n","    # 폴더 내의 모든 파일들을 순회\n","    for file_name in os.listdir(folder_path):\n","        # 파일의 전체 경로를 생성\n","        file_path = os.path.join(folder_path, file_name)\n","\n","        # ZIP 파일인지 확인\n","        if zipfile.is_zipfile(file_path):\n","            # ZIP 파일의 이름을 따서 추출할 디렉토리를 생성\n","            extract_to = os.path.join(extract_to_base, os.path.splitext(file_name)[0])\n","\n","            # 디렉토리가 존재하지 않으면 생성\n","            if not os.path.exists(extract_to):\n","                os.makedirs(extract_to)\n","\n","            # ZIP 파일을 읽고 압축 해제\n","            with zipfile.ZipFile(file_path, 'r') as zip_ref:\n","                zip_ref.extractall(extract_to)\n","                print(f'{file_name} 파일이 {extract_to} 경로로 성공적으로 추출되었습니다.')\n","\n","# 사용 예제\n","folder_path = '/content/drive/MyDrive/01.데이터/2.Validation/원천데이터'  # ZIP 파일들이 있는 폴더 경로\n","extract_to_base = '/content/drive/MyDrive/01.데이터/2.Validation/원천데이터'  # 파일을 추출할 기본 디렉토리 경로\n","\n","unzip_all_files_in_folder(folder_path, extract_to_base)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"is9Of-oHx3J0","executionInfo":{"status":"ok","timestamp":1720416554601,"user_tz":-540,"elapsed":140234,"user":{"displayName":"크복짜","userId":"12410456823605642737"}},"outputId":"89e0a0d0-c0f2-47a2-95dc-bc8b2730002a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["VS_02. FACEBOOK.zip 파일이 /content/drive/MyDrive/01.데이터/2.Validation/원천데이터/VS_02. FACEBOOK 경로로 성공적으로 추출되었습니다.\n","VS_04. BAND.zip 파일이 /content/drive/MyDrive/01.데이터/2.Validation/원천데이터/VS_04. BAND 경로로 성공적으로 추출되었습니다.\n","VS_03. INSTAGRAM.zip 파일이 /content/drive/MyDrive/01.데이터/2.Validation/원천데이터/VS_03. INSTAGRAM 경로로 성공적으로 추출되었습니다.\n","VS_05. NATEON.zip 파일이 /content/drive/MyDrive/01.데이터/2.Validation/원천데이터/VS_05. NATEON 경로로 성공적으로 추출되었습니다.\n","VS_01. KAKAO.zip 파일이 /content/drive/MyDrive/01.데이터/2.Validation/원천데이터/VS_01. KAKAO 경로로 성공적으로 추출되었습니다.\n"]}]},{"cell_type":"code","source":["!pip install datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g4fWuZQp10I2","executionInfo":{"status":"ok","timestamp":1721019651350,"user_tz":-540,"elapsed":9552,"user":{"displayName":"크복짜","userId":"12410456823605642737"}},"outputId":"84be0b88-cb54-41e0-bee5-7f0ed7e26157"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n","Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"]}]},{"cell_type":"code","source":["import os\n","from datasets import Dataset\n","from tqdm import tqdm\n","import time\n","from datasets import load_dataset\n","import pandas as pd"],"metadata":{"id":"_54yHs3i1Wbl","executionInfo":{"status":"ok","timestamp":1721019652318,"user_tz":-540,"elapsed":969,"user":{"displayName":"크복짜","userId":"12410456823605642737"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["folder=['/content/drive/MyDrive/01.데이터/2.Validation/원천데이터/VS_01. KAKAO',\n","        '/content/drive/MyDrive/01.데이터/2.Validation/원천데이터/VS_02. FACEBOOK',\n","        '/content/drive/MyDrive/01.데이터/2.Validation/원천데이터/VS_03. INSTAGRAM',\n","        '/content/drive/MyDrive/01.데이터/2.Validation/원천데이터/VS_04. BAND',\n","        '/content/drive/MyDrive/01.데이터/2.Validation/원천데이터/VS_05. NATEON']"],"metadata":{"id":"bMq4vt_604bk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = {\"Q\": [], \"A\": [], \"id\": []}"],"metadata":{"id":"lMkRba-K2VcS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["id_counter = 1\n","for folder_path in folder:\n","    for file in tqdm(os.listdir(folder_path)):\n","        if file.endswith(\".txt\"):\n","            file_path = os.path.join(folder_path, file)\n","            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n","                lines = f.readlines()\n","                prev_line = \"\"\n","                prev_label = None\n","                for line in lines:\n","                    line = line.strip()\n","                    if line:\n","                        try:\n","                            label = int(line.split(\":\")[0])\n","                            text = line[len(str(label)) + 3 :].strip()\n","                            if prev_line == \"\":\n","                                prev_line = text\n","                            else:\n","                                data[\"id\"].append(id_counter)\n","                                data[\"Q\"].append(prev_line)\n","                                data[\"A\"].append(text)\n","                                id_counter += 1\n","                                prev_line = \"\"\n","                        except ValueError:\n","                            continue\n","\n","\n","# 데이터셋 생성\n","dataset = Dataset.from_dict(data)\n","\n","# 데이터셋을 CSV 파일로 저장\n","df = pd.DataFrame(data)\n","csv_filename = \"makedata.csv\"\n","df.to_csv(csv_filename, index=False, encoding=\"utf-8\")\n","\n","print(dataset[0])\n","len(dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uH8QYJzyv0mv","executionInfo":{"status":"ok","timestamp":1720417558100,"user_tz":-540,"elapsed":266961,"user":{"displayName":"크복짜","userId":"12410456823605642737"}},"outputId":"4e2f56ab-e7b1-4fd9-bcc2-1bb4a9179bbd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 7605/7605 [03:16<00:00, 38.65it/s] \n","100%|██████████| 1000/1000 [00:18<00:00, 55.52it/s]\n","100%|██████████| 600/600 [00:09<00:00, 63.92it/s] \n","100%|██████████| 204/204 [00:02<00:00, 69.00it/s] \n","100%|██████████| 201/201 [00:02<00:00, 90.32it/s] \n"]},{"output_type":"stream","name":"stdout","text":["{'Q': '오늘 저녁에 오랜만에 영화 고고?', 'A': '오우 너무 좋지? ㅎ', 'id': 1}\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"lzw-jvhJzrcx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install pytorch_lightning"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CBLOjiiG4gyf","executionInfo":{"status":"ok","timestamp":1721025423372,"user_tz":-540,"elapsed":87141,"user":{"displayName":"크복짜","userId":"12410456823605642737"}},"outputId":"21283cf9-fb72-4290-b333-e58d8da43f70"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch_lightning\n","  Downloading pytorch_lightning-2.3.3-py3-none-any.whl (812 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.3/812.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (1.25.2)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2.2.1+cu121)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.66.2)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0.1)\n","Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2023.6.0)\n","Collecting torchmetrics>=0.7.0 (from pytorch_lightning)\n","  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (24.0)\n","Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.11.0)\n","Collecting lightning-utilities>=0.10.0 (from pytorch_lightning)\n","  Downloading lightning_utilities-0.11.4-py3-none-any.whl (26 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2.31.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.9.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (67.7.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (3.14.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (3.1.3)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.0.0->pytorch_lightning)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.0.0->pytorch_lightning)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.0.0->pytorch_lightning)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.0.0->pytorch_lightning)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.0.0->pytorch_lightning)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.0.0->pytorch_lightning)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.0.0->pytorch_lightning)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.0.0->pytorch_lightning)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.0.0->pytorch_lightning)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch>=2.0.0->pytorch_lightning)\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.0.0->pytorch_lightning)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->pytorch_lightning)\n","  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->pytorch_lightning) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->pytorch_lightning) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch_lightning\n","Successfully installed lightning-utilities-0.11.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 pytorch_lightning-2.3.3 torchmetrics-1.4.0.post0\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch\n","from pytorch_lightning import Trainer, LightningModule\n","from pytorch_lightning.callbacks import ModelCheckpoint\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel, AdamW\n","import re, os\n","from tqdm import tqdm\n","from torch.optim.lr_scheduler import ReduceLROnPlateau"],"metadata":{"id":"P4PwhYToLugW","executionInfo":{"status":"ok","timestamp":1721026676554,"user_tz":-540,"elapsed":345,"user":{"displayName":"크복짜","userId":"12410456823605642737"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["\n","\n","Q_TKN = \"<usr>\"\n","A_TKN = \"<sys>\"\n","BOS = \"</s>\"\n","EOS = \"</s>\"\n","MASK = \"<unused0>\"\n","SENT = \"<unused1>\"\n","PAD = \"<pad>\"\n","\n","save_dir = \"saved_models\"\n","os.makedirs(save_dir, exist_ok=True)\n","\n","class ChatbotDataset(Dataset):\n","    def __init__(self, chats, max_len=40):\n","        self._data = chats\n","        self.max_len = max_len\n","        self.q_token = Q_TKN\n","        self.a_token = A_TKN\n","        self.sent_token = SENT\n","        self.eos = EOS\n","        self.mask = MASK\n","        self.tokenizer = koGPT2_TOKENIZER\n","\n","    def __len__(self):\n","        return len(self._data)\n","\n","    def __getitem__(self, idx):\n","        turn = self._data.iloc[idx]\n","        q = turn[\"Q\"]\n","        q = re.sub(r\"([?.!,])\", r\" \", q)\n","\n","        a = turn[\"A\"]\n","        a = re.sub(r\"([?.!,])\", r\" \", a)\n","\n","        q_toked = self.tokenizer.tokenize(self.q_token + q + self.sent_token)\n","        q_len = len(q_toked)\n","\n","        a_toked = self.tokenizer.tokenize(self.a_token + a + self.eos)\n","        a_len = len(a_toked)\n","\n","        if q_len > self.max_len:\n","            a_len = self.max_len - q_len\n","            if a_len <= 0:\n","                q_toked = q_toked[-(int(self.max_len / 2)):]\n","                q_len = len(q_toked)\n","                a_len = self.max_len - q_len\n","            a_toked = a_toked[:a_len]\n","            a_len = len(a_toked)\n","\n","        if q_len + a_len > self.max_len:\n","            a_len = self.max_len - q_len\n","            if a_len <= 0:\n","                q_toked = q_toked[-(int(self.max_len / 2)):]\n","                q_len = len(q_toked)\n","                a_toked = a_toked[:a_len]\n","                a_len = len(a_toked)\n","\n","        labels = [self.mask] * q_len + a_toked[1:]\n","        mask = [0] * q_len + [1] * a_len + [0] * (self.max_len - q_len - a_len)\n","        labels_ids = self.tokenizer.convert_tokens_to_ids(labels)\n","        while len(labels_ids) < self.max_len:\n","            labels_ids += [self.tokenizer.pad_token_id]\n","\n","        token_ids = self.tokenizer.convert_tokens_to_ids(q_toked + a_toked)\n","        while len(token_ids) < self.max_len:\n","            token_ids += [self.tokenizer.pad_token_id]\n","\n","        return token_ids, np.array(mask), labels_ids\n","\n","def collate_batch(batch):\n","    max_len = max(len(item[0]) for item in batch)\n","    data = [item[0] + [koGPT2_TOKENIZER.pad_token_id] * (max_len - len(item[0])) for item in batch]\n","    mask = [item[1].tolist() + [0] * (max_len - len(item[1])) for item in batch]\n","    label = [item[2] + [koGPT2_TOKENIZER.pad_token_id] * (max_len - len(item[2])) for item in batch]\n","    return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","\n","\n","class KoGPT2Chat(LightningModule):\n","    def __init__(self, learning_rate=3e-5):\n","        super(KoGPT2Chat, self).__init__()\n","        self.save_hyperparameters()  # 하이퍼파라미터 저장\n","        self.neg = -1e18\n","        self.model = GPT2LMHeadModel.from_pretrained(\"skt/kogpt2-base-v2\")\n","        self.tokenizer = koGPT2_TOKENIZER\n","        self.criterion = torch.nn.CrossEntropyLoss(reduction=\"none\")\n","\n","    def forward(self, inputs):\n","        return self.model(inputs)\n","\n","    def training_step(self, batch, batch_idx):\n","        token_ids, mask, label = batch\n","        out = self(token_ids)\n","        out = out.logits\n","        mask_3d = mask.unsqueeze(dim=2).repeat_interleave(repeats=out.shape[2], dim=2)\n","        mask_out = torch.where(mask_3d == 1, out, self.neg * torch.ones_like(out))\n","        loss = self.criterion(mask_out.transpose(2, 1), label)\n","        avg_loss = loss.sum() / mask.sum()\n","        self.log('train_loss', avg_loss)\n","        return avg_loss\n","\n","    def configure_optimizers(self):\n","        optimizer = AdamW(self.parameters(), lr=0.001)\n","        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n","        return {\n","            'optimizer': optimizer,\n","            'lr_scheduler': {\n","                'scheduler': scheduler,\n","                'monitor': 'train_loss'\n","            }\n","        }\n","\n","koGPT2_TOKENIZER = PreTrainedTokenizerFast.from_pretrained(\n","    \"skt/kogpt2-base-v2\",\n","    bos_token=BOS,\n","    eos_token=EOS,\n","    unk_token=\"<unk>\",\n","    pad_token=PAD,\n","    mask_token=MASK,\n",")\n","\n","dataname = \"/content/drive/MyDrive/Colab Notebooks/makedata.csv\"  # Adjusted file path\n","Chatbot_Data = pd.read_csv(dataname)\n","Chatbot_Data = Chatbot_Data[:100]\n","Chatbot_Data.dropna(subset=[\"A\"], inplace=True)\n","Chatbot_Data.dropna(subset=[\"Q\"], inplace=True)\n","Chatbot_Data.dropna(subset=[\"id\"], inplace=True)\n","\n","train_set = ChatbotDataset(Chatbot_Data, max_len=40)\n","train_dataloader = DataLoader(\n","    train_set,\n","    batch_size=16,  # 배치 크기를 줄여 VRAM 사용량 감소\n","    num_workers=0,\n","    shuffle=True,\n","    collate_fn=collate_batch,\n",")\n","\n","model = KoGPT2Chat(learning_rate=3e-5)\n","\n","# 체크포인트 콜백 정의\n","checkpoint_callback = ModelCheckpoint(\n","    dirpath=save_dir,\n","    filename=\"chatbot_model-{epoch:02d}-{train_loss:.2f}\",\n","    save_top_k=3,\n","    monitor=\"train_loss\",\n","    mode=\"min\",\n",")\n","\n","# PyTorch Lightning Trainer 설정 및 학습\n","trainer = Trainer(max_epochs=3, accelerator=\"gpu\", devices=1, precision=16, callbacks=[checkpoint_callback])\n","trainer.fit(model, train_dataloader)\n","\n","print(\"Model saved at:\", save_dir)"],"metadata":{"id":"JWyZ2djNFAXg","colab":{"base_uri":"https://localhost:8080/","height":581,"referenced_widgets":["bdb75de324854b95aab378a0706c5080","5aed3385d84f45fdb3292b365dd85d8b","048e8e1bdcdf492781ab93a0803d4492","56bb996cd6004cdf88ee59b4c9897a6b","a2eb50d55d514335b36ce94b25b32d11","b3c0b619e4044312a451a31fbc93312c","731a415653374b75ae18f984f554b01a","ec492490d6644fdeb968305cce6b9229","d3461e7ff76446928a3e0412f1923cfe","55d6042cecb34ac8aaf8f075b0a8ec17","622a670c4ccf431398cb05679b3b66ff"]},"executionInfo":{"status":"ok","timestamp":1721027304834,"user_tz":-540,"elapsed":431350,"user":{"displayName":"크복짜","userId":"12410456823605642737"}},"outputId":"afe0b469-b390-4309-f641-0c621914a649"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n","/usr/local/lib/python3.10/dist-packages/lightning_fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n","INFO:pytorch_lightning.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /content/saved_models exists and is not empty.\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | GPT2LMHeadModel  | 125 M  | eval \n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","125 M     Trainable params\n","0         Non-trainable params\n","125 M     Total params\n","500.656   Total estimated model params size (MB)\n","/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"]},{"output_type":"display_data","data":{"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdb75de324854b95aab378a0706c5080"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=3` reached.\n"]},{"output_type":"stream","name":"stdout","text":["Model saved at: saved_models\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"18SN08xm4BVZ"}},{"cell_type":"code","source":["# 학습 완료된 모델 로드\n","model_path = get_latest_checkpoint_path(save_dir)\n","model = KoGPT2Chat.load_from_checkpoint(model_path)\n","model.eval()\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","# 챗봇 인터페이스\n","def chatbot_response(model, tokenizer, question):\n","    input_ids = tokenizer.encode(Q_TKN + question + SENT, return_tensors='pt').to(device)\n","    with torch.no_grad():\n","        response_ids = model.model.generate(input_ids, max_length=50, pad_token_id=tokenizer.pad_token_id, eos_token_id=tokenizer.eos_token_id)\n","    response = tokenizer.decode(response_ids[0], skip_special_tokens=True)\n","    return response\n","\n","# 콘솔 기반 챗봇 인터페이스\n","print(\"Chatbot is ready! Type 'exit' to quit.\")\n","while True:\n","    user_input = input(\"You: \")\n","    if user_input.lower() == 'exit':\n","        break\n","    response = chatbot_response(model, koGPT2_TOKENIZER, user_input)\n","    print(f\"Chatbot: {response}\")"],"metadata":{"id":"8xkiXr4efpA-","colab":{"base_uri":"https://localhost:8080/","height":244},"executionInfo":{"status":"ok","timestamp":1721027368357,"user_tz":-540,"elapsed":63538,"user":{"displayName":"크복짜","userId":"12410456823605642737"}},"outputId":"bdb8c0a8-5dd4-46f9-e380-78cb3dcfb170"},"execution_count":21,"outputs":[{"name":"stdout","output_type":"stream","text":["Chatbot is ready! Type 'exit' to quit.\n","You: 안녕\n","Chatbot: 안녕                                               \n","You: 어제 머했니?\n","Chatbot: 어제 머했니?                                           \n","You: 영화 봤니?\n","Chatbot: 영화 봤니?                                           \n","You: 영화 추천해줘\n","Chatbot: 영화 추천해줘                                            \n","You: quit\n","Chatbot: quit                                             \n","You: exit\n"]}]},{"cell_type":"code","source":["\n","# 데이터프레임의 열 이름 확인\n","print(data.columns)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vbmu4--v5DJL","executionInfo":{"status":"ok","timestamp":1721021774676,"user_tz":-540,"elapsed":325,"user":{"displayName":"크복짜","userId":"12410456823605642737"}},"outputId":"f2b18ccd-21ee-405e-9f58-b14e6f63c656"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['Q', 'A', 'id'], dtype='object')\n"]}]},{"cell_type":"code","source":["# print('out',out.shape)\n","#         print(label.shape)\n","#         print(mask.shape)\n","#         print(mask_3d.shape)\n","#         print(mask_out.shape)\n","#         print(mask_out.transpose(2, 1).shape)\n","#         print(label.shape)"],"metadata":{"id":"WQSiO6_ZYxi3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 1 데이터 더 찾기\n","# 2 데이터 증식\n","# 3 레그?? 어떻게 쓰는지 찾아보기\n","# 4 파이토치 공부하기\n","# 4 프론트 엔지니어링으로 대화 톤 바꾸기 ex)고분고분, 겸손"],"metadata":{"id":"TMqoJbBukt-a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # transformers/modeling_gpt2.py\n","# def forward(\n","#     self,\n","#     input_ids=None,\n","#     past_key_values=None,\n","#     attention_mask=None,\n","#     token_type_ids=None,\n","#     position_ids=None,\n","#     head_mask=None,\n","#     inputs_embeds=None,\n","#     labels=None,\n","#     use_cache=None,\n","#     output_attentions=None,\n","#     output_hidden_states=None,\n","#     return_dict=None,\n","# ):\n","#     # 모델의 출력\n","#     transformer_outputs = self.transformer(\n","#         input_ids,\n","#         past_key_values=past_key_values,\n","#         attention_mask=attention_mask,\n","#         token_type_ids=token_type_ids,\n","#         position_ids=position_ids,\n","#         head_mask=head_mask,\n","#         inputs_embeds=inputs_embeds,\n","#         use_cache=use_cache,\n","#         output_attentions=output_attentions,\n","#         output_hidden_states=output_hidden_states,\n","#         return_dict=return_dict,\n","#     )\n","#     hidden_states = transformer_outputs[0]\n","#     lm_logits = self.lm_head(hidden_states)\n","\n","#     loss = None\n","#     if labels is not None:\n","#         # Shift so that tokens < n predict n\n","#         shift_logits = lm_logits[..., :-1, :].contiguous()\n","#         shift_labels = labels[..., 1:].contiguous()\n","#         loss_fct = CrossEntropyLoss()\n","#         loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n","\n","#     if not return_dict:\n","#         output = (lm_logits,) + transformer_outputs[1:]\n","#         return ((loss,) + output) if loss is not None else output\n","\n","#     return CausalLMOutputWithCrossAttentions(\n","#         loss=loss,\n","#         logits=lm_logits,\n","#         past_key_values=transformer_outputs.past_key_values,\n","#         hidden_states=transformer_outputs.hidden_states,\n","#         attentions=transformer_outputs.attentions,\n","#         cross_attentions=transformer_outputs.cross_attentions,\n","#     )"],"metadata":{"id":"mAQe3FX3g4Gb"},"execution_count":null,"outputs":[]}]}