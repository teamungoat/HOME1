{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1UQRlq4u_OdTUvJLmUuy_DlgirrKt60ra","authorship_tag":"ABX9TyPCTqSwBYU/U2TV/ESvyLI5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"QZdJAqfXmNbB","executionInfo":{"status":"ok","timestamp":1720676402742,"user_tz":-540,"elapsed":9550,"user":{"displayName":"크복짜","userId":"12410456823605642737"}}},"outputs":[],"source":["import math\n","import numpy as np\n","import pandas as pd\n","import random\n","import re\n","import torch\n","import urllib.request\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import PreTrainedTokenizerFast\n","import urllib.request\n","import zipfile\n","import os\n"]},{"cell_type":"code","source":["import zipfile"],"metadata":{"id":"TP6m-OYvy4zZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["folder ='/content/drive/MyDrive/01.데이터/2.Validation/원천데이터'"],"metadata":{"id":"pvUN3Wn8uKh_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def unzip_all_files_in_folder(folder_path, extract_to_base):\n","    # 폴더 내의 모든 파일들을 순회\n","    for file_name in os.listdir(folder_path):\n","        # 파일의 전체 경로를 생성\n","        file_path = os.path.join(folder_path, file_name)\n","\n","        # ZIP 파일인지 확인\n","        if zipfile.is_zipfile(file_path):\n","            # ZIP 파일의 이름을 따서 추출할 디렉토리를 생성\n","            extract_to = os.path.join(extract_to_base, os.path.splitext(file_name)[0])\n","\n","            # 디렉토리가 존재하지 않으면 생성\n","            if not os.path.exists(extract_to):\n","                os.makedirs(extract_to)\n","\n","            # ZIP 파일을 읽고 압축 해제\n","            with zipfile.ZipFile(file_path, 'r') as zip_ref:\n","                zip_ref.extractall(extract_to)\n","                print(f'{file_name} 파일이 {extract_to} 경로로 성공적으로 추출되었습니다.')\n","\n","# 사용 예제\n","folder_path = '/content/drive/MyDrive/01.데이터/2.Validation/원천데이터'  # ZIP 파일들이 있는 폴더 경로\n","extract_to_base = '/content/drive/MyDrive/01.데이터/2.Validation/원천데이터'  # 파일을 추출할 기본 디렉토리 경로\n","\n","unzip_all_files_in_folder(folder_path, extract_to_base)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"is9Of-oHx3J0","executionInfo":{"status":"ok","timestamp":1720416554601,"user_tz":-540,"elapsed":140234,"user":{"displayName":"크복짜","userId":"12410456823605642737"}},"outputId":"89e0a0d0-c0f2-47a2-95dc-bc8b2730002a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["VS_02. FACEBOOK.zip 파일이 /content/drive/MyDrive/01.데이터/2.Validation/원천데이터/VS_02. FACEBOOK 경로로 성공적으로 추출되었습니다.\n","VS_04. BAND.zip 파일이 /content/drive/MyDrive/01.데이터/2.Validation/원천데이터/VS_04. BAND 경로로 성공적으로 추출되었습니다.\n","VS_03. INSTAGRAM.zip 파일이 /content/drive/MyDrive/01.데이터/2.Validation/원천데이터/VS_03. INSTAGRAM 경로로 성공적으로 추출되었습니다.\n","VS_05. NATEON.zip 파일이 /content/drive/MyDrive/01.데이터/2.Validation/원천데이터/VS_05. NATEON 경로로 성공적으로 추출되었습니다.\n","VS_01. KAKAO.zip 파일이 /content/drive/MyDrive/01.데이터/2.Validation/원천데이터/VS_01. KAKAO 경로로 성공적으로 추출되었습니다.\n"]}]},{"cell_type":"code","source":["!pip install datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"g4fWuZQp10I2","executionInfo":{"status":"ok","timestamp":1720676462651,"user_tz":-540,"elapsed":13319,"user":{"displayName":"크복짜","userId":"12410456823605642737"}},"outputId":"b65729fc-1341-49ff-f281-7bcea1e3bdac"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/547.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/547.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m522.2/547.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n","Collecting pyarrow>=15.0.0 (from datasets)\n","  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n","Collecting requests>=2.32.2 (from datasets)\n","  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n","Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.6.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, requests, pyarrow, dill, multiprocess, datasets\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.31.0\n","    Uninstalling requests-2.31.0:\n","      Successfully uninstalled requests-2.31.0\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 14.0.2\n","    Uninstalling pyarrow-14.0.2:\n","      Successfully uninstalled pyarrow-14.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n","google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n","ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-2.20.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-16.1.0 requests-2.32.3 xxhash-3.4.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pyarrow","requests"]},"id":"42d02a8bfca14c5288c38d73de137c9d"}},"metadata":{}}]},{"cell_type":"code","source":["import os\n","from datasets import Dataset\n","from tqdm import tqdm\n","import time\n","from datasets import load_dataset\n","import pandas as pd"],"metadata":{"id":"_54yHs3i1Wbl","executionInfo":{"status":"ok","timestamp":1720676483033,"user_tz":-540,"elapsed":1713,"user":{"displayName":"크복짜","userId":"12410456823605642737"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["folder=['/content/drive/MyDrive/01.데이터/2.Validation/원천데이터/VS_01. KAKAO',\n","        '/content/drive/MyDrive/01.데이터/2.Validation/원천데이터/VS_02. FACEBOOK',\n","        '/content/drive/MyDrive/01.데이터/2.Validation/원천데이터/VS_03. INSTAGRAM',\n","        '/content/drive/MyDrive/01.데이터/2.Validation/원천데이터/VS_04. BAND',\n","        '/content/drive/MyDrive/01.데이터/2.Validation/원천데이터/VS_05. NATEON']"],"metadata":{"id":"bMq4vt_604bk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = {\"Q\": [], \"A\": [], \"id\": []}"],"metadata":{"id":"lMkRba-K2VcS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["id_counter = 1\n","for folder_path in folder:\n","    for file in tqdm(os.listdir(folder_path)):\n","        if file.endswith(\".txt\"):\n","            file_path = os.path.join(folder_path, file)\n","            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n","                lines = f.readlines()\n","                prev_line = \"\"\n","                prev_label = None\n","                for line in lines:\n","                    line = line.strip()\n","                    if line:\n","                        try:\n","                            label = int(line.split(\":\")[0])\n","                            text = line[len(str(label)) + 3 :].strip()\n","                            if prev_line == \"\":\n","                                prev_line = text\n","                            else:\n","                                data[\"id\"].append(id_counter)\n","                                data[\"Q\"].append(prev_line)\n","                                data[\"A\"].append(text)\n","                                id_counter += 1\n","                                prev_line = \"\"\n","                        except ValueError:\n","                            continue\n","\n","\n","# 데이터셋 생성\n","dataset = Dataset.from_dict(data)\n","\n","# 데이터셋을 CSV 파일로 저장\n","df = pd.DataFrame(data)\n","csv_filename = \"makedata.csv\"\n","df.to_csv(csv_filename, index=False, encoding=\"utf-8\")\n","\n","print(dataset[0])\n","len(dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uH8QYJzyv0mv","executionInfo":{"status":"ok","timestamp":1720417558100,"user_tz":-540,"elapsed":266961,"user":{"displayName":"크복짜","userId":"12410456823605642737"}},"outputId":"4e2f56ab-e7b1-4fd9-bcc2-1bb4a9179bbd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 7605/7605 [03:16<00:00, 38.65it/s] \n","100%|██████████| 1000/1000 [00:18<00:00, 55.52it/s]\n","100%|██████████| 600/600 [00:09<00:00, 63.92it/s] \n","100%|██████████| 204/204 [00:02<00:00, 69.00it/s] \n","100%|██████████| 201/201 [00:02<00:00, 90.32it/s] \n"]},{"output_type":"stream","name":"stdout","text":["{'Q': '오늘 저녁에 오랜만에 영화 고고?', 'A': '오우 너무 좋지? ㅎ', 'id': 1}\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"lzw-jvhJzrcx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install pytorch_lightning"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CBLOjiiG4gyf","executionInfo":{"status":"ok","timestamp":1720676304531,"user_tz":-540,"elapsed":73038,"user":{"displayName":"크복짜","userId":"12410456823605642737"}},"outputId":"d4c473f6-d306-4c70-9fdc-90b79e40285e"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch_lightning\n","  Downloading pytorch_lightning-2.3.3-py3-none-any.whl (812 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.3/812.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (1.25.2)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2.3.0+cu121)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.66.4)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0.1)\n","Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2023.6.0)\n","Collecting torchmetrics>=0.7.0 (from pytorch_lightning)\n","  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (24.1)\n","Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.12.2)\n","Collecting lightning-utilities>=0.10.0 (from pytorch_lightning)\n","  Downloading lightning_utilities-0.11.3.post0-py3-none-any.whl (26 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2.31.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.9.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (67.7.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (3.15.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (3.1.4)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.0.0->pytorch_lightning)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.0.0->pytorch_lightning)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.0.0->pytorch_lightning)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.0.0->pytorch_lightning)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.0.0->pytorch_lightning)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.0.0->pytorch_lightning)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.0.0->pytorch_lightning)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.0.0->pytorch_lightning)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.0.0->pytorch_lightning)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.0.0->pytorch_lightning)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.0.0->pytorch_lightning)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch_lightning) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->pytorch_lightning)\n","  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->pytorch_lightning) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (2024.6.2)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->pytorch_lightning) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch_lightning\n","Successfully installed lightning-utilities-0.11.3.post0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 pytorch_lightning-2.3.3 torchmetrics-1.4.0.post0\n"]}]},{"cell_type":"code","source":["from pytorch_lightning import LightningModule"],"metadata":{"id":"oWfHL8Lk5fLQ","executionInfo":{"status":"ok","timestamp":1720676509131,"user_tz":-540,"elapsed":4282,"user":{"displayName":"크복짜","userId":"12410456823605642737"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch\n","from pytorch_lightning import Trainer\n","from pytorch_lightning.callbacks import ModelCheckpoint\n","\n","from torch.utils.data import DataLoader, Dataset\n","from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\n","from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n","import re, os\n","from tqdm import tqdm\n","\n","\n","Q_TKN = \"<usr>\"\n","A_TKN = \"<sys>\"\n","BOS = \"</s>\"\n","EOS = \"</s>\"\n","MASK = \"<unused0>\"\n","SENT = \"<unused1>\"\n","PAD = \"<pad>\"\n","\n","save_dir = \"saved_models\"\n","os.makedirs(save_dir, exist_ok=True)\n","\n","\n","print(\"start1\")\n","\n","\n","class ChatbotDataset(Dataset):\n","    def __init__(self, chats, max_len=40):  # 데이터셋의 전처리를 해주는 부분\n","        self._data = chats\n","        self.max_len = max_len\n","        self.q_token = Q_TKN\n","        self.a_token = A_TKN\n","        self.sent_token = SENT\n","        self.eos = EOS\n","        self.mask = MASK\n","        self.tokenizer = koGPT2_TOKENIZER\n","\n","    def __len__(self):  # chatbotdata 의 길이를 리턴한다.\n","        return len(self._data)\n","\n","    def __getitem__(self, idx):  # 로드한 챗봇 데이터를 차례차례 DataLoader로 넘겨주는 메서드\n","        turn = self._data.iloc[idx]\n","        q = turn[\"Q\"]  # 질문을 가져온다.\n","        q = re.sub(r\"([?.!,])\", r\" \", q)  # 구둣점들을 제거한다.\n","\n","        a = turn[\"A\"]  # 답변을 가져온다.\n","        a = re.sub(r\"([?.!,])\", r\" \", a)  # 구둣점들을 제거한다.\n","\n","        q_toked = self.tokenizer.tokenize(self.q_token + q + self.sent_token)\n","        q_len = len(q_toked)\n","\n","        a_toked = self.tokenizer.tokenize(self.a_token + a + self.eos)\n","        a_len = len(a_toked)\n","\n","        # 질문의 길이가 최대길이보다 크면\n","        if q_len > self.max_len:\n","            a_len = self.max_len - q_len  # 답변의 길이를 최대길이 - 질문길이\n","            if a_len <= 0:  # 질문의 길이가 너무 길어 질문만으로 최대 길이를 초과 한다면\n","                q_toked = q_toked[-(int(self.max_len / 2)) :]  # 질문길이를 최대길이의 반으로\n","                q_len = len(q_toked)\n","                a_len = self.max_len - q_len  # 답변의 길이를 최대길이 - 질문길이\n","            a_toked = a_toked[:a_len]\n","            a_len = len(a_toked)\n","\n","        # 질문의 길이 + 답변의 길이가 최대길이보다 크면\n","        if q_len + a_len > self.max_len:\n","            a_len = self.max_len - q_len  # 답변의 길이를 최대길이 - 질문길이\n","            if a_len <= 0:  # 질문의 길이가 너무 길어 질문만으로 최대 길이를 초과 한다면\n","                q_toked = q_toked[-(int(self.max_len / 2)) :]  # 질문길이를 최대길이의 반으로\n","                q_len = len(q_toked)\n","                a_len = self.max_len - q_len  # 답변의 길이를 최대길이 - 질문길이\n","            a_toked = a_toked[:a_len]\n","            a_len = len(a_toked)\n","\n","        # 답변 labels = [mask, mask, ...., mask, ..., <bos>,..답변.. <eos>, <pad>....]\n","        labels = [\n","            self.mask,\n","        ] * q_len + a_toked[1:]\n","\n","        # mask = 질문길이 0 + 답변길이 1 + 나머지 0\n","        mask = [0] * q_len + [1] * a_len + [0] * (self.max_len - q_len - a_len)\n","        # 답변 labels을 index 로 만든다.\n","        labels_ids = self.tokenizer.convert_tokens_to_ids(labels)\n","        # 최대길이만큼 PADDING\n","        while len(labels_ids) < self.max_len:\n","            labels_ids += [self.tokenizer.pad_token_id]\n","\n","        # 질문 + 답변을 index 로 만든다.\n","        token_ids = self.tokenizer.convert_tokens_to_ids(q_toked + a_toked)\n","        # 최대길이만큼 PADDING\n","        while len(token_ids) < self.max_len:\n","            token_ids += [self.tokenizer.pad_token_id]\n","\n","        # 질문+답변, 마스크, 답변\n","        return (token_ids, np.array(mask), labels_ids)\n","\n","\n","def collate_batch(batch):\n","    data = [item[0] for item in batch]\n","    mask = [item[1] for item in batch]\n","    label = [item[2] for item in batch]\n","    return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","\n","\n","koGPT2_TOKENIZER = PreTrainedTokenizerFast.from_pretrained(\n","    \"skt/kogpt2-base-v2\",\n","    bos_token=BOS,\n","    eos_token=EOS,\n","    unk_token=\"<unk>\",\n","    pad_token=PAD,\n","    mask_token=MASK,\n",")\n","model = GPT2LMHeadModel.from_pretrained(\"skt/kogpt2-base-v2\")\n","\n","dataname = \"/content/makedata.csv\"  # Adjusted file path\n","Chatbot_Data = pd.read_csv(dataname)\n","Chatbot_Data = Chatbot_Data[:100]\n","Chatbot_Data.dropna(subset=[\"A\"], inplace=True)\n","Chatbot_Data.dropna(subset=[\"Q\"], inplace=True)\n","Chatbot_Data.dropna(subset=[\"id\"], inplace=True)\n","\n","\n","print(\"start3\")\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","train_set = ChatbotDataset(Chatbot_Data, max_len=40)\n","train_dataloader = DataLoader(\n","    train_set,\n","    batch_size=32,\n","    num_workers=0,\n","    shuffle=True,\n","    collate_fn=collate_batch,\n",")\n","\n","model.to(device)\n","\n","learning_rate = 3e-5\n","criterion = torch.nn.CrossEntropyLoss(reduction=\"none\")\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","num_epochs = 3\n","Sneg = -1e18\n","\n","for epoch in range(num_epochs):\n","    dataloader = tqdm(train_dataloader, desc=f\"Epoch {epoch}\")\n","    for batch_idx, samples in enumerate(dataloader):\n","        optimizer.zero_grad()\n","        token_ids, mask, label = samples\n","        token_ids, mask, label = token_ids.to(device), mask.to(device), label.to(device)\n","        out = model(token_ids)\n","        out = out.logits\n","        mask_3d = mask.unsqueeze(dim=2).repeat_interleave(repeats=out.shape[2], dim=2)\n","        mask_out = torch.where(mask_3d == 1, out, Sneg * torch.ones_like(out))\n","        loss = criterion(mask_out.transpose(2, 1), label)\n","        print(out.shape)\n","        print(label.shape)\n","        print(mask.shape)\n","        print(mask_3d.shape)\n","        print(mask_out.shape)\n","        print(mask_out.transpose(2, 1).shape)\n","        print(label.shape)\n","        avg_loss = loss.sum() / mask.sum()\n","        print('avg_loss', avg_loss)\n","        avg_loss.backward()\n","        optimizer.step()\n","\n","model_save_path = os.path.join(save_dir, \"chatbot_model.pth\")\n","torch.save(\n","    {\n","        \"model_state_dict\": model.state_dict(),\n","        \"optimizer_state_dict\": optimizer.state_dict(),\n","        \"epoch\": epoch,\n","    },\n","    model_save_path,\n",")\n","\n","print(\"Model saved at:\", model_save_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4AXMtFpD3XZq","executionInfo":{"status":"ok","timestamp":1720677974633,"user_tz":-540,"elapsed":15528,"user":{"displayName":"크복짜","userId":"12410456823605642737"}},"outputId":"570f9da3-d649-4d59-c99c-1084acfe92e9","collapsed":true},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n"]},{"output_type":"stream","name":"stdout","text":["start1\n","start3\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 0:  25%|██▌       | 1/4 [00:00<00:00,  4.20it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([32, 40, 51200])\n","torch.Size([32, 40])\n","torch.Size([32, 40])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 51200, 40])\n","torch.Size([32, 40])\n","avg_loss tensor(27.6917, device='cuda:0', grad_fn=<DivBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch 0:  50%|█████     | 2/4 [00:00<00:00,  3.32it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([32, 40, 51200])\n","torch.Size([32, 40])\n","torch.Size([32, 40])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 51200, 40])\n","torch.Size([32, 40])\n","avg_loss tensor(23.2024, device='cuda:0', grad_fn=<DivBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch 0:  75%|███████▌  | 3/4 [00:00<00:00,  3.18it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([32, 40, 51200])\n","torch.Size([32, 40])\n","torch.Size([32, 40])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 51200, 40])\n","torch.Size([32, 40])\n","avg_loss tensor(28.7776, device='cuda:0', grad_fn=<DivBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 0: 100%|██████████| 4/4 [00:01<00:00,  3.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["torch.Size([4, 40, 51200])\n","torch.Size([4, 40])\n","torch.Size([4, 40])\n","torch.Size([4, 40, 51200])\n","torch.Size([4, 40, 51200])\n","torch.Size([4, 51200, 40])\n","torch.Size([4, 40])\n","avg_loss tensor(30.8157, device='cuda:0', grad_fn=<DivBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch 1:   0%|          | 0/4 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([32, 40, 51200])\n","torch.Size([32, 40])\n","torch.Size([32, 40])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 51200, 40])\n","torch.Size([32, 40])\n","avg_loss tensor(23.7948, device='cuda:0', grad_fn=<DivBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1:  50%|█████     | 2/4 [00:00<00:00,  3.89it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([32, 40, 51200])\n","torch.Size([32, 40])\n","torch.Size([32, 40])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 51200, 40])\n","torch.Size([32, 40])\n","avg_loss tensor(27.8083, device='cuda:0', grad_fn=<DivBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch 1:  75%|███████▌  | 3/4 [00:00<00:00,  3.44it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([32, 40, 51200])\n","torch.Size([32, 40])\n","torch.Size([32, 40])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 51200, 40])\n","torch.Size([32, 40])\n","avg_loss tensor(22.8963, device='cuda:0', grad_fn=<DivBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1: 100%|██████████| 4/4 [00:01<00:00,  3.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["torch.Size([4, 40, 51200])\n","torch.Size([4, 40])\n","torch.Size([4, 40])\n","torch.Size([4, 40, 51200])\n","torch.Size([4, 40, 51200])\n","torch.Size([4, 51200, 40])\n","torch.Size([4, 40])\n","avg_loss tensor(30.7660, device='cuda:0', grad_fn=<DivBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch 2:   0%|          | 0/4 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([32, 40, 51200])\n","torch.Size([32, 40])\n","torch.Size([32, 40])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 51200, 40])\n","torch.Size([32, 40])\n","avg_loss tensor(23.4601, device='cuda:0', grad_fn=<DivBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2:  50%|█████     | 2/4 [00:00<00:00,  3.92it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([32, 40, 51200])\n","torch.Size([32, 40])\n","torch.Size([32, 40])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 51200, 40])\n","torch.Size([32, 40])\n","avg_loss tensor(22.3027, device='cuda:0', grad_fn=<DivBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch 2:  75%|███████▌  | 3/4 [00:00<00:00,  3.35it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([32, 40, 51200])\n","torch.Size([32, 40])\n","torch.Size([32, 40])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 40, 51200])\n","torch.Size([32, 51200, 40])\n","torch.Size([32, 40])\n","avg_loss tensor(24.3373, device='cuda:0', grad_fn=<DivBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2: 100%|██████████| 4/4 [00:01<00:00,  3.53it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([4, 40, 51200])\n","torch.Size([4, 40])\n","torch.Size([4, 40])\n","torch.Size([4, 40, 51200])\n","torch.Size([4, 40, 51200])\n","torch.Size([4, 51200, 40])\n","torch.Size([4, 40])\n","avg_loss tensor(29.6866, device='cuda:0', grad_fn=<DivBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Model saved at: saved_models/chatbot_model.pth\n"]}]},{"cell_type":"code","source":["# print('out',out.shape)\n","#         print(label.shape)\n","#         print(mask.shape)\n","#         print(mask_3d.shape)\n","#         print(mask_out.shape)\n","#         print(mask_out.transpose(2, 1).shape)\n","#         print(label.shape)"],"metadata":{"id":"WQSiO6_ZYxi3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["token_ids\n","token_ids.shape\n","out.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZEB_whnIUy1r","executionInfo":{"status":"ok","timestamp":1720676809170,"user_tz":-540,"elapsed":449,"user":{"displayName":"크복짜","userId":"12410456823605642737"}},"outputId":"2262e9d4-b1d6-4a3f-e1ac-bf5d9feb05e4"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4, 40, 51200])"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["label.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NzYMY2dyVNtR","executionInfo":{"status":"ok","timestamp":1720676840753,"user_tz":-540,"elapsed":328,"user":{"displayName":"크복짜","userId":"12410456823605642737"}},"outputId":"bae9426c-1b04-4fa2-afa2-4a5ca4081ff0"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4, 40])"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["mask_3d.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0QLvLOfFVp2j","executionInfo":{"status":"ok","timestamp":1720676953714,"user_tz":-540,"elapsed":332,"user":{"displayName":"크복짜","userId":"12410456823605642737"}},"outputId":"4a117ea9-efd7-4702-ad21-cf1f06c0227c"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4, 40, 51200])"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["mask_out.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oNpy4RVQV7XJ","executionInfo":{"status":"ok","timestamp":1720677118114,"user_tz":-540,"elapsed":301,"user":{"displayName":"크복짜","userId":"12410456823605642737"}},"outputId":"2b63bf30-2a31-46f3-9df2-433e719513d4"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4, 40, 51200])"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["mask_out.transpose(2, 1).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rRpJzpyLWg7U","executionInfo":{"status":"ok","timestamp":1720677182464,"user_tz":-540,"elapsed":300,"user":{"displayName":"크복짜","userId":"12410456823605642737"}},"outputId":"37b0bcea-feee-4179-dce9-e9b2597fe4c8"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4, 51200, 40])"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["mask.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FbtQ6_vfWTn3","executionInfo":{"status":"ok","timestamp":1720677126054,"user_tz":-540,"elapsed":327,"user":{"displayName":"크복짜","userId":"12410456823605642737"}},"outputId":"af755d3e-525e-4553-ee57-2a3507670feb"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4, 40])"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["train_set[0]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HEyNUW19qUNV","executionInfo":{"status":"ok","timestamp":1720676897437,"user_tz":-540,"elapsed":350,"user":{"displayName":"크복짜","userId":"12410456823605642737"}},"outputId":"a80f999f-8bf1-4fe5-e302-f800cdf3d4bd"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([2,\n","  10070,\n","  44596,\n","  12474,\n","  20486,\n","  10584,\n","  17577,\n","  739,\n","  10,\n","  4,\n","  9114,\n","  8092,\n","  12371,\n","  18364,\n","  739,\n","  739,\n","  608,\n","  1,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3],\n"," array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n"," [9,\n","  9,\n","  9,\n","  9,\n","  9,\n","  9,\n","  9,\n","  9,\n","  9,\n","  9114,\n","  8092,\n","  12371,\n","  18364,\n","  739,\n","  739,\n","  608,\n","  1,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3,\n","  3])"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["import torch\n","from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n","\n","# Define your special tokens and tokenizer\n","Q_TKN = \"<usr>\"\n","A_TKN = \"<sys>\"\n","SENT = \"<unused1>\"\n","EOS = \"</s>\"\n","BOS = \"</s>\"\n","\n","# Initialize your tokenizer\n","koGPT2_TOKENIZER = PreTrainedTokenizerFast.from_pretrained(\n","    \"skt/kogpt2-base-v2\",\n","    bos_token=BOS,\n","    eos_token=EOS,\n","    unk_token=\"<unk>\",\n","    pad_token=\"<pad>\",\n","    mask_token=\"<unused0>\",\n",")\n","\n","# Load your trained model\n","model_path = \"saved_models/chatbot_model.pth\"  # Adjust the path to your saved model\n","model = GPT2LMHeadModel.from_pretrained(\"skt/kogpt2-base-v2\")\n","checkpoint = torch.load(model_path)\n","model.load_state_dict(checkpoint[\"model_state_dict\"])\n","model.eval()\n","\n","# Interaction loop with the chatbot\n","with torch.no_grad():\n","    while 1:\n","        q = input(\"user > \").strip()\n","        if q == \"quit\":\n","            break\n","        a = \"\"\n","        while 1:\n","            input_ids = torch.LongTensor(\n","                koGPT2_TOKENIZER.encode(Q_TKN + q + SENT + A_TKN + a)\n","            ).unsqueeze(dim=0)\n","            pred = model(input_ids)\n","            pred = pred.logits\n","            gen = koGPT2_TOKENIZER.convert_ids_to_tokens(\n","                torch.argmax(pred, dim=-1).squeeze().numpy().tolist()\n","            )[-1]\n","            if gen == EOS:\n","                break\n","            a += gen.replace(\"▁\", \" \")\n","        print(\"Chatbot > {}\".format(a.strip()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jwffEEwq2CQa","outputId":"b0bfb227-6a1c-4f38-85c1-efbf929ab470"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n"]},{"output_type":"stream","name":"stdout","text":["user > 범죄도시 재밌냐?\n","Chatbot > 나 그런 거 안 봤어\n","user > 범죄 도시 같은 영화 추천 해줘\n","Chatbot > 나 범죄 도시  제일 최근에 본 영화야\n","user > 다른 영화 없어?\n","Chatbot > 나 외국 영화 좋아하잖아~\n","user > 한국영화는 안 좋아하냐?\n","Chatbot > 응응 영화가 제일 재밌어\n","user > 어제는 모 했어?\n","Chatbot > 오늘부터인가\n","user > 아침 밥은 먹었어?\n","Chatbot > 응 근데 나 오메가쓰리 많이 먹어서 요즘 오메가쓰리 많이 먹는 중\n","user > 개킹받네\n","Chatbot > 그럼 그 강아지 쌉가능\n","user > 내놔 임마\n","Chatbot > 그럼 너가 대신 들어가 줄게\n","user > ㅋㅋㅋ\n","Chatbot > 아유 키키 그래도 이번 추석은 잘 버틸 수 있겠어\n"]}]},{"cell_type":"code","source":["# 1 데이터 더 찾기\n","# 2 데이터 증식\n","# 3 레그?? 어떻게 쓰는지 찾아보기\n","# 4 파이토치 공부하기\n","# 4 프론트 엔지니어링으로 대화 톤 바꾸기 ex)고분고분, 겸손"],"metadata":{"id":"TMqoJbBukt-a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Model(nn.Module):\n","    def __init__(self):\n","        super(Model, self).__init__()\n","        self.layer1=nn.Sequential(\n","            nn.Conv2d(in_channels=3, out_channels=64, kerner_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )"],"metadata":{"id":"DI7656VKltdS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torchmetrics\n","preds=torch.rand(10,5).softmax(dim=1)\n","labels=torch.randint(5,(10,))\n","\n","acc=torchmetrics.functional.accuracy(preds, target)"],"metadata":{"id":"3uwp9p05qgku"},"execution_count":null,"outputs":[]}]}