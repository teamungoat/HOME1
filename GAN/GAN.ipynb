{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"scrolled":true,"id":"IRybAxhVs1Ju","outputId":"c94a3db3-1107-4f5e-cd68-1a635185bbf8","colab":{"base_uri":"https://localhost:8080/","height":606},"executionInfo":{"status":"error","timestamp":1722479450337,"user_tz":-540,"elapsed":4443,"user":{"displayName":"크복짜","userId":"12410456823605642737"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"functional_35\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_35\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ sequential_2 (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │         \u001b[38;5;34m865,281\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ sequential_3 (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │         \u001b[38;5;34m212,865\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ sequential_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">865,281</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ sequential_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">212,865</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,078,146\u001b[0m (4.11 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,078,146</span> (4.11 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m852,609\u001b[0m (3.25 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">852,609</span> (3.25 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m225,537\u001b[0m (881.00 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">225,537</span> (881.00 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x7a69c3251fc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x7a69c3251990> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"error","ename":"TypeError","evalue":"must be real number, not list","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-134b41da7793>\u001b[0m in \u001b[0;36m<cell line: 90>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m               \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/GAn/gan_mnist_%d.png\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m \u001b[0mgan_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 2000번 반복되고, 배치 사이즈는 32,  200번마다 결과가 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-3-134b41da7793>\u001b[0m in \u001b[0;36mgan_train\u001b[0;34m(epoch, batch_size, saving_interval)\u001b[0m\n\u001b[1;32m     67\u001b[0m           \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch:%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' d_loss:%.4f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' g_loss:%.4f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# 이 부분은 중간 과정을 이미지로 저장해 주는 부분\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: must be real number, not list"]}],"source":["from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n","from tensorflow.keras.layers import BatchNormalization, Activation, LeakyReLU, UpSampling2D, Conv2D\n","from tensorflow.keras.models import Sequential, Model\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# 생성자 모델\n","generator = Sequential()\n","generator.add(Dense(128*7*7, input_dim=100, activation=LeakyReLU(0.2)))\n","generator.add(BatchNormalization())\n","generator.add(Reshape((7, 7, 128)))\n","generator.add(UpSampling2D())\n","generator.add(Conv2D(64, kernel_size=5, padding='same'))\n","generator.add(BatchNormalization())\n","generator.add(Activation(LeakyReLU(0.2)))\n","generator.add(UpSampling2D())\n","generator.add(Conv2D(1, kernel_size=5, padding='same', activation='tanh'))\n","\n","# 판별자 모델\n","discriminator = Sequential()\n","discriminator.add(Conv2D(64, kernel_size=5, strides=2, input_shape=(28,28,1), padding=\"same\"))\n","discriminator.add(Activation(LeakyReLU(0.2)))\n","discriminator.add(Dropout(0.3))\n","discriminator.add(Conv2D(128, kernel_size=5, strides=2, padding=\"same\"))\n","discriminator.add(Activation(LeakyReLU(0.2)))\n","discriminator.add(Dropout(0.3))\n","discriminator.add(Flatten())\n","discriminator.add(Dense(1, activation='sigmoid'))\n","discriminator.compile(loss='binary_crossentropy', optimizer='adam')\n","discriminator.trainable = False\n","\n","# 생성자와 판별자 모델을 연결시키는 gan 모델\n","ginput = Input(shape=(100,))\n","dis_output = discriminator(generator(ginput))\n","gan = Model(ginput, dis_output)\n","gan.compile(loss='binary_crossentropy', optimizer='adam')\n","gan.summary()\n","\n","# 신경망을 실행시키는 함수\n","def gan_train(epoch, batch_size, saving_interval):\n","\n","  # MNIST 데이터를 불러옵니다.\n","\n","  (X_train, _), (_, _) = mnist.load_data()  # 앞서 불러온 적 있는 MNIST를 다시 이용합니다. 단, 테스트 과정은 필요 없고 이미지만 사용할 것이기 때문에 X_train만 불러왔습니다.\n","  X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n","  X_train = (X_train - 127.5) / 127.5  # 픽셀 값은 0에서 255 사이의 값입니다. 이전에 255로 나누어 줄때는 이를 0~1 사이의 값으로 바꾸었던 것인데, 여기서는 127.5를 빼준 뒤 127.5로 나누어 줌으로 인해 -1에서 1사이의 값으로 바뀌게 됩니다.\n","  # X_train.shape, Y_train.shape, X_test.shape, Y_test.shape\n","\n","  true = np.ones((batch_size, 1))\n","  fake = np.zeros((batch_size, 1))\n","\n","  for i in range(epoch):\n","          # 실제 데이터를 판별자에 입력하는 부분\n","          idx = np.random.randint(0, X_train.shape[0], batch_size)\n","          imgs = X_train[idx]\n","          d_loss_real = discriminator.train_on_batch(imgs, true)\n","\n","          # 가상 이미지를 판별자에 입력하는 부분\n","          noise = np.random.normal(0, 1, (batch_size, 100))\n","          gen_imgs = generator.predict(noise)\n","          d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n","\n","          # 판별자와 생성자의 오차를 계산\n","          d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","          g_loss = gan.train_on_batch(noise, true)\n","\n","          print('epoch:%d' % i, ' d_loss:%.4f' % d_loss, ' g_loss:%.4f' % g_loss)\n","\n","        # 이 부분은 중간 과정을 이미지로 저장해 주는 부분\n","        #이미지들은 gan_images 폴더에 저장\n","          if i % saving_interval == 0:\n","              #r, c = 5, 5\n","              noise = np.random.normal(0, 1, (25, 100))\n","              gen_imgs = generator.predict(noise)\n","\n","              # Rescale images 0 - 1\n","              gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","              fig, axs = plt.subplots(5, 5)\n","              count = 0\n","              for j in range(5):\n","                  for k in range(5):\n","                      axs[j, k].imshow(gen_imgs[count, :, :, 0], cmap='gray')\n","                      axs[j, k].axis('off')\n","                      count += 1\n","              fig.savefig(\"/content/drive/MyDrive/GAn/gan_mnist_%d.png\" % i)\n","\n","gan_train(2001, 32, 200)  # 2000번 반복되고, 배치 사이즈는 32,  200번마다 결과가 저장\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ONYs9gB8s1J3"},"outputs":[],"source":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OVYMuEn0xUBe","executionInfo":{"status":"ok","timestamp":1722479383445,"user_tz":-540,"elapsed":17483,"user":{"displayName":"크복짜","userId":"12410456823605642737"}},"outputId":"f03f4d61-f314-4115-bde0-f6f96e730164"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}